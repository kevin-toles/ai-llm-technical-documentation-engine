[
  {
    "chapter_number": 1,
    "title": "Toward a Microservices Architecture",
    "start_page": 17,
    "end_page": 24,
    "summary": "Toward a Microservices Architecture\nThe goal of this book is to help you build a working microservices architecture.\nRecently, the microservices style of building software has exploded in popularity.\nthe early 2010s, the term microservices emerged as a way to describe a new style of\nmicroservices style have skyrocketed.\nin between have been learning and implementing microservices-style architectures.\ndicted that the global market for microservices architectures will grow to $8.07 billion\nlot of interest, a lot of adoption, and lots and lots of microservices work.\nFor many, building software in the microservices way has turned out to be a chal‐\nThe truth is that implementing a microservices system isn’t easy.\nmake microservices seem like a bad idea.\nBut the benefits of building microservices make the risks worthwhile.\nMicroservices\nTo build that architecture, you’ll need to make important deci‐\nwith microservices through iterative experimentation.\nof building a microservices-based application.\nIn this book, we’ve documented the decisions that form a strong microservices foun‐\nWhat Are Microservices?\npiece, they describe microservices as:\nmicroservices possess.\nTheir list starts with the core microservice characteristic of\nChapter 1: Toward a Microservices Architecture\nFor contrast, here is another definition for microservices from the book Microservice\nA microservice is an independently deployable component of bounded scope that sup‐\nMicroservice architec‐\ncapability-aligned microservices.\ntinction between microservices and the architecture that enables them.\nThese are just two examples from a sea of microservices definitions.\nyou’ve built a textbook microservices system.\ncharacteristics to be able to identify a microservices system when we see one.\nWe think that question of why you’d build microservices is much more\nefits to microservices, we believe the best reason to build software this way is to\nWhat Are Microservices?\nCompanies around the world have had success implementing microservices architec‐\nmental benefit of the microservices style: a reduction in coordination costs.\nBuilding software the microservices way is just one option.\nThis is where a microservices system can shine.\nBuilding complex software is hard work.\nthe mostly autonomous teams need to coordinate their work (see Figure 1-1).\nChapter 1: Toward a Microservices Architecture\nchoosing one way or the other, teams did not even face the choice most of the time?\nexactly what microservices architecture is all about, in its essence.\nUnderstanding that the fundamental force of building successful microservices archi‐\nBuilding complex distributed systems such as a microservices\ndecision I am facing going to reduce coordination costs for my teams or not?” The\nUltimately, microservices have become popular because they help businesses succeed.\nThe microservices style enables companies operating in complex\nfront work, focus, and decision making to build a microservices architecture that can\nOne of the biggest hurdles that first-time microservices adopters face is dealing with\nthe enormous scope and breadth of a microservices system.\nOne big challenge is that impactful decisions in a microservices system aren’t\nlibrary up to date across all of your microservices and teams turns out to be a\nAt its heart, a microservices system is a complex adaptive system.\nmicroservices system design difficult.\nChapter 1: Toward a Microservices Architecture\nthe complex system we need to design, it’s easy to see why microservices architec‐\nbest practices for building a microservices architecture.\nUltimately, the real challenge of building a microservices architecture is that of deal‐\nthe work that happens in a microservices system easier, safer, cheaper, and faster.\nSo far, we’ve established that the microservices style can help you deliver software\ngood microservices architecture is difficult and fraught with challenging and complex\nMany of the successful microservices implementers we’ve talked to have\nIf you had unlimited time, you could build a great microservices architecture solely\nmethodology, and build microservices of various sizes.\nwith a system that works for you as well as a lot of experience building microservice\nyou build the expertise you need to build better microservices?\nTo help address this challenge, we’ve developed a prescriptive microservices model.\nWe’ve made decisions about team design, process, architecture, infrastructure, and\nexperiences building microservices systems for large organizations.\nTo help bring our microservices examples to life, we’ll be using the\nOur goal is to guide you in building your first microservices implementation as\ntogether is only the first of many microservices systems that you’ll build.\nThe “Up and Running” Microservices Model\nThe scope of a microservices architecture is quite large.\nareas that are the most relevant to a microservices system and have the biggest impact\nmicroservices model.\nmental factors that influence microservice coordination.\nChapter 1: Toward a Microservices Architecture",
    "keywords": [
      "Microservices",
      "Microservices Architecture",
      "microservices system",
      "system",
      "Architecture",
      "coordination costs",
      "microservices style",
      "build",
      "building",
      "team",
      "coordination",
      "’ll",
      "microservices model",
      "decisions",
      "building microservice systems"
    ],
    "concepts": [
      "microservices",
      "microservice",
      "architecture",
      "architectures",
      "architectural",
      "design",
      "designed",
      "teams",
      "team",
      "complex"
    ]
  },
  {
    "chapter_number": 3,
    "title": "This",
    "start_page": 25,
    "end_page": 30,
    "summary": "we’ll take a look at the data factors you’ll need to consider in a microservices sys‐\nTo get there, we’ll need to make a lot of decisions.\nSo, the first tool we’ll need is a way\nBut decisions aren’t always easy to make.\nwe need a way of capturing the decisions that matter so we can re-evaluate and\nTo address that need, we’re going to use a tool called an architecture decision record\nthe idea of documenting design decisions has been around for a long time.\nan extremely useful tool and a good way of getting clarity on the decisions that need\nA good decision record needs to capture four important elements:\nA decision record should give us a summary of these contextual\nA good decision\nEvery decision record needs to document\nDecisions have consequences and a decision record should document the impor‐\nHow will our decision choice impact the way\nwe work or other decisions that need to be made?\nYou can create decision records however you like.\ndescribed you’ll have a good decision record.\ndecision record (LADR).\nnice concise way of documenting a decision record.\nWriting a Lightweight Architectural Decision Record\nThe first key decision we’ll record is the decision to keep a record of decisions.\nmore simply, we’ll create an ADR that says we intend to keep track of our decisions.\nIt lets us keep track of decisions in simple text files\ndecision records in the same way we manage source code.\n# OPM1: Use ADRS for decision tracking\n## Decision\nThese are the key elements of our decision record.\nsystem the decision relates to.\nThe Status header of our record lets us know what life-cycle stage this decision is in.\nFor example, if you’re drafting a new decision that you need to get agreement on, you\ndecision, you might change its status to Under Review.\nmade the decision for you, so we’ve set the status to Accepted.\nIn our case, we want to capture the need to log important decisions\ndecisions.\nWe'll need a way to keep track of the important decision\nWith the context in place, we can move on to recording the actual decision we’ve\n## Decision\ndecision record (LADR) format.\nquences is that we’ll need to spend time actually documenting our decisions and\n* We'll need to write decision records for key decisions\n* We'll need a source code management solution to manage decision record files\nlog of the key decisions we make.\nInstead we’ll highlight that a key decision has been made as in the following\nKey Decision: Use ADRs for Decision Tracking\nUse ADRs to log the key decisions we’ve made in our system design and build.\nYou’ll be able to find a detailed version of each decision record at this book’s GitHub\nFinally, we introduced the concept of the architectural decision record",
    "keywords": [
      "decision record",
      "decision",
      "decisions",
      "’ll",
      "architectural decision record",
      "record",
      "microservices",
      "Chapter",
      "LADR",
      "good decision record",
      "architectural decision",
      "lightweight architectural decision",
      "key decision",
      "design",
      "’ve"
    ],
    "concepts": [
      "decisions",
      "decision record",
      "microservice",
      "microservices",
      "use",
      "useful",
      "records",
      "recording",
      "based",
      "tool"
    ]
  },
  {
    "chapter_number": 2,
    "title": "Designing a Microservices Operating Model",
    "start_page": 31,
    "end_page": 72,
    "summary": "Designing a Microservices Operating Model\ndesign and build microservices as well as the infrastructure and tools you need to\nFor example, an operating model can define the responsibilities of teams.\nthe work needed to build microservices happens on top of the team structures, pro‐\nmost important parts of a microservices system—how the teams are designed and\nThat’s what we’ll be covering in this chapter: the relationship between teams and\nWe’ll introduce a tool called Team Topologies and by\nthe end of the chapter we’ll have a team-based design that we can use as the founda‐\nYou don’t need to actually assemble the people and teams we’ve\nLet’s get started by taking a look at why teams and team design are so important in\nWhy Teams and People Matter\nteams.\nSo we’ll need to start by considering the types of teams and structure that will\nIn a microservices system, culture and team design matters.\nThe idea that team design and culture is important isn’t a new one.\ntured the impact of team structure on system design eloquently in his now-famous\nteams communicate.\nFor example, consider a microservices team that must consult a\ncentralized team of database experts whenever they need to change a data model.\nChapter 2: Designing a Microservices Operating Model\npeople factors that have the biggest impact on a microservices system: team size, team\nTeam Size\nturns out that the size of the teams building those services matters a lot too.\nIf you have too many people on a team, they’ll need to spend more time communicat‐\n“Rightsizing” teams is an important\npany teams to keep them effective.\nkeep the rate of change high, we’ll need to limit the size of the teams in our system.\nour microservices model, we’re going to keep the size of teams to somewhere between\nWhy Teams and People Matter \nKey Decision: Team Size Should Be Limited\nThe teams that perform work in our system should have no more than eight people\nKeeping the team size down will help us limit the internal interaction needed.\nteams if they have to spend all their time coordinating with each other.\nAnother side effect of making our teams smaller is that it limits the number of spe‐\nWith less people on the team, we’ll need to make sure we have\nTeam Skills\nA team can only be as good as its members.\nIf we want high-performing teams, we’ll\nneed to pay special attention to the way we decide who gets to be on a team.\nexample, which roles and specializations will our teams need?\nGood team design in these two companies will prob‐\nFor example, a cross-functional team could contain UX designers,\nChapter 2: Designing a Microservices Operating Model\nA big advantage of building a team this way is that you can make better decisions\nexperts on each team.\nSo, rather than dictate exactly which roles you’ll need on your teams, we’ll make two\nence shows that microservices work better when teams can make good decisions on\nWe don’t need observers on the team or people who\nKey Decision: Principles for Team Membership Should Be Defined\nthe team’s deliverable, service, or product.\nWith the right size and the right people, we should be able to build effective teams\nAs the number of teams grow, we’ll also need to consider\nhow teams coordinate with each other.\nThat’s the last team property we need to\nBuilding a team with the right size and filling it with the right people will help us cre‐\nBut it’s the communication among teams, rather than\nWhy Teams and People Matter \nvices teams will be able to deliver changes faster.\nIt would be nice if our microservices teams could act completely autonomously and\nIf teams were free to make their own design, development, testing,\nWe might want our microservices teams to act independently, but we\nMicroservices teams working independently can pick the right tools for the\nteam.\nour teams design and build their own cloud-based network architectures, we’ve lost\nIt’s possible to build an organization that enables efficient team\nautonomy (and responsibility) to form teams, choose work, and\nand continuous tuning of your team design.\nMost importantly, optimizing team coordination requires an active design effort.\nWhen that happens, the team design forms around the technology that’s been\nChapter 2: Designing a Microservices Operating Model\nTo avoid this problem, we’ll address team coordination and team design as the first\nfocus on team design and coordination can really help you succeed with your micro‐\nKey Decision: When to Design Teams and Coordination Models\nTeam and coordination design should start before the design of the system architec‐\nThe team and coordination models must continually be upda‐\ndesigning microservices team models called Team Topologies.\nIntroducing Team Topologies\nSince we’re going to start our design work with a focus on teams, we’ll need a way of\ning team designs.\nFor our model, we’ll use a design tool called Team Topologies.\nTeam Topologies is a design approach invented by Matthew Skelton and Manuel Pais.\nWe like using it because it provides a formal language for talking about team design,\nwith a special focus on the way teams work with each other.\nWe won’t be using every aspect of the Team Topologies approach in our design work.\nInstead, we’ll be drawing on three elements: team types, team interaction modes, and\nmicroservices teams.\nNext, we’ll look at different parts of the Team Topology approach, starting with the\ntypes of teams we can define.\nTeam Types\nThere are four team types defined in\nTeam Topologies: stream-aligned, enabling, complicated-subsystem, and platform.\nIntroducing Team Topologies \nA stream-aligned team owns and runs a deliverable piece of work.\nFor example, microservices teams are usually stream-aligned as\nAn enabling team supports the work of other teams with a consulting engage‐\nFor example, an enabling architecture team can help\nmicroservices teams understand emerging technical standards and conventions\nThis type of team works on a domain or on subject matter that is difficult to\nembedded in every team.\nscale that skill across all teams, most organizations create a complicated-\nsubsystem security team who can engage with individual teams as needed.\nLike enabling teams, the platform team provides support to the rest of the orga‐\nnization, with one important difference—platform teams deliver a self-service\nplatform becomes a product, whose users are the rest of the teams in the organi‐\nFor example, operations teams can become platform teams when they\noffer build and release tools to development teams for them to use.\nWith an understanding of these four team types, we can start communicating how we\nwant our teams to operate.\nTo really communicate our team design, we will need one\nmore part of the model: the ways in which teams interact with each other, which we’ll\nChapter 2: Designing a Microservices Operating Model\nOur goal in designing teams for the microservices build is to reduce the amount of\nThe Team Topology team\nteams are coordinating with each other.\nThat’s where the Team Topology interaction\nThis interaction mode requires both teams to work closely together.\nrequires high levels of coordination from each team and is difficult to scale.\nexample, a security team might collaborate with a microservices team to develop\nInstead of teams working together to solve a shared problem, one team plays a\na facilitating interaction would be when an infrastructure team helps a microser‐\nof interaction, one team provides a service to other teams in the organization\nFor example, an enabling architecture team might document a list of recom‐\nmended software patterns and offer those to all microservices teams in a “pat‐\nuse to paint a picture of what our microservices teams should look like, with particu‐\nlar emphasis on when and how much our teams will need to coordinate.\nsection, we’ll use the terms we’ve borrowed from Team Topology to design a micro‐\nservices team model.\nIntroducing Team Topologies \nDesigning a Microservices Team Topology\nIn this section, we’re going to create a design for our microservices teams that\ncommunicates the teams we need and how they will work together.\nwe’ll have a diagram that highlights the main points of team coordination and\nTo create a team design and Team Topology, we’ll follow this step-by-step approach:\n1. Establish a system design team.\n2. Create a microservices team template for future teams.\n3. Define platform teams.\n5. Add key consumer teams.\nAs we go through each of the steps, we’ll be documenting our team design and build‐\ning our Team Topology.\nFor each step we’ll identify one or more teams, create and\npopulate a team design document, and draw the key interactions for that team.\nget started by focusing on the system design team.\nEstablish a System Design Team\nthis group the system design team.\nChapter 2: Designing a Microservices Operating Model\nIn our model, the system design team has three core reponsibilities:\nDesign team structures\nThe system design team is the first team we’re putting together.\nIt’s also the team\nthat we expect to design the teams that will do the work of building the system.\nThat’s the work we’ll be doing in our subsequent team design steps.\nwe’re playing the role of the system design team together.\nIn addition to forming teams, the system design team should shape the decisions\nthat individual teams can make.\nFinally, the system design team needs to continually improve all the team\nIt’s useful to document these team responsibilities so that we can clearly communicate\nwhat each team does.\nteams to make it easier to understand and improve them as the system evolves.\nLet’s start by deciding on a Team Topology type.\ndesigns and standards, we expect the system design team to focus on helping other\nteams build microservices and supporting components.\nAlthough the system design team delivers a system, the work we want them to\ndo is characteristic of an enabling team type.\nWe also want the system design team to be small.\nTo that end, we’ll limit the size of the team to between three to\nDesigning a Microservices Team Topology \nLet’s capture these decisions and team properties by creating a lightweight design\ndocument for the system design team.\ncreate a file named system-design-team.md and populate it with the following content:\n# System Design Team\n## Team Type\n## Team Size\n* Design team structures\ndecide how you want to manage your team design files.\nples for our team designs in our GitHub repository.\nAt this point, we’d typically diagram the team visually and map out its interactions\nwith other teams in the system.\nThis is the heart of our team design work and allows\nus to visualize how teams will work together.\ndesign team to use a facilitating interaction model with microservices teams.\nsince this is the first team we’ve defined, we don’t have anything to interact with.\nWith the system design team document created, we can move on to documenting and\ndiagramming our microservices teams.\nBuilding a Microservices Team Template\nIn the “up and running” model, every microservice is owned by a team.\nteam owns the decisions and work of designing, building, delivering, and maintain‐\nIn practice, a single team may own multiple microservices.\nthe responsibility for a microservice is not shared across multiple teams.\nChapter 2: Designing a Microservices Operating Model\nEach microservice will be owned by a single team, who will design, build, and run it.\nThis team is responsible for the microservice for the lifetime of the service.\nend up with lots of microservices teams.\nces teams operating in our system, we won’t design each of them individually.\nwe’ll define a microservices team template that can be applied to any new teams we\nmicroservices teams later on when we need them.\nsome essential team properties.\nJust like before, we’ll document the team type, team\nAs we mentioned before, our microservices teams are\nWith that characteristic, it makes sense to classify the microservices team as stream-\nWe’ll also stick to the team-sizing decision we made earlier in this chapter\nand keep the team size between five to eight people.\nCreate a file named microservice-team-template.md and pop‐\n# Microservices Team Template\n## Team Type\n## Team Size\n* Designing and developing microservice(s)\nDesigning a Microservices Team Topology \nWith the template definition documented, we can start diagramming our team inter‐\nWe have used yellow for this; each type of team\nA stream-aligned microservices team\nIn the previous section we defined our system design team.\nmicroservices team diagrammed, we can add the systems team into the picture.\nthe system design team using a vertical rectangle, as shown in Figure 2-2.\nThe enabling system design team\nUse a unique color (we have used violet) for the system design team to denote that it’s\nan enabling team.\nWe’ve placed it vertically and to the left of the microservices team\nto show an interaction between the two teams.\ndesign team to facilitate the microservices teams.\nteams will need to interact is enough now.\nOur color choices for the team types in this chapter are based on\nteam” box with the actual names of your teams and the services they are working on.\nChapter 2: Designing a Microservices Operating Model\nbetween your microservices teams.\nWe use a particular color to denote that our microservices team is stream-aligned.\nWe’ll be updating this diagram as we go through the team design steps, so keep your\nNow that we have our first two teams modeled, let’s take a look at the cloud platform\nteam.\nPlatform Teams\nPlatform teams are an important part of a microservices system.\nservices work is done by independent, stream-aligned teams.\nOur facilitating system design team can\nenable some of their decision making, but the microservices teams will still need to\nThat’s where platform team types can help.\nA platform team can make those common components avail‐\nable for microservices to use “as a service.” The service model improves the scalability\nIn our model, we’ve decided to instantiate a cloud platform team that offers a net‐\nThe key point for now is that the teams in our sys‐\nices that our platform team provides.\nWith those details understood, we can document our cloud platform team in a file\n# Cloud Platform Team\n## Team Type\n## Team Size\nDesigning a Microservices Team Topology \nThis is a key part of a platform team’s responsibil‐\nAs we’ve done before, we’ll add the cloud platform team to the Team Topology dia‐\nBut this time we need to model a platform team.\nblue) below the microservices teams and connected to the system design team, as\nThe cloud platform team offering a service\nces teams.\nThis is to show that the platform team is implementing the x-as-a-service\nmodel for its interaction with the microservices team.\nthe system design team will be enabling the work of the platform team.\nteam.\nBut, in practice, you’ll probably need to roll out multiple platform teams to\nkeep the teams to a manageable size.\nsider how multiple platform teams will coordinate together to offer services to the\nChapter 2: Designing a Microservices Operating Model\nWith the three teams we’ve designed, we have enough people in place to be able to\ntional capabilities that we want a team to own.\nIn our microservices model, we’ve decided to create a specialized release team.\nadditional team owns the responsibility of releasing (or deploying) microservices into\nWhile a microservices team could deploy its own\ndirectly into production, microservices teams deliver a built and tested container.\nstream-aligned teams to make that work happen.\n# Release Team\n## Team Type\n## Team Size\nNext, we’ll add the release team to the developing picture of our Team Topology.\nComplicated-subsystem teams are modeled with yet another specific color.\nDesigning a Microservices Team Topology \nthe end of the microservices team’s box, as shown in Figure 2-4.\nThe release team\nsituation, you’ll need to change the team design and shift the responsibilities for\ndeployment to the individual microservices teams.\nThe release team is the final team at the core of our microservices model.\nish our design, we need to consider the teams that will have to use our microservices.\nConsumer Teams\nsumers of our microservices and how they’ll interact with our system teams.\nof our microservices system is the API team.\nThe API team is responsible for exposing our microservices to other development\nteams as an application programming interface (API).\ntion development team would interact with the API released by this team and never\nworth detailing the properties of our API team and its responsibilities.\nby creating a file named api-team.md and populating it as follows:\nChapter 2: Designing a Microservices Operating Model\n# API Team\n## Team Type\n## Team Size\nJust like the microservices team, the API team is a stream-aligned team.\nA special nuance of the API team is that, because the API\nneeds to call microservices to function, it is dependent on the microservices team.\nWe can model these interaction properties in our Team Topology model by adding\nanother rectangle at the top of our diagram to represent the API team.\nthe same color as the microservices team (we’ve used yellow), as it is also a stream-\naligned team.\nTo reflect the dependency between our microservices and API teams,\ncates that the microservices team will need to make sure their services are invocable\nThe finished Team Topology with the API team\nWith this final team defined an in the picture, our topology looks a lot like the fin‐\nWith our basic Team Topology defined, we can see how this work ties back to the\nDesigning a Microservices Team Topology \nTaken together, the decisions, team definitions, and topologies we’ve just created\nWith it, we’ve defined the teams that need\nteams to work together.\nworthwhile drawing out more than one Team Topology diagram to reflect different\nthat the cloud platform, system design, and release teams provide.\nOur lightweight approach to the Team Topology and\nteam designs does just that.\ndesigning the actual microservices.\nChapter 2: Designing a Microservices Operating Model\nDesigning Microservices:\nIn this chapter, we introduce an evolutionary process for designing microservices.\nKey Decision: Use a Standard Process for Service Design\nThe microservices design system described in this chapter is a top-down, multistep\nChapter 3: Designing Microservices: The SEED(S) Process\ndesign APIs as what we use in product management.\nStart service design by identifying key actors in your domain, to achieve customer-\nChapter 3: Designing Microservices: The SEED(S) Process\nAny effective API or service design methodology, including SEED(S), is based on a\nChapter 3: Designing Microservices: The SEED(S) Process\nChapter 3: Designing Microservices: The SEED(S) Process\nwith a good design, we need to understand the service interaction patterns of our\nWe recommend this kind of approach because modeling in a microservices team is a\nteam activity.\nChapter 3: Designing Microservices: The SEED(S) Process\nrequirements for a microservice, or an API, in the form of a set of actions and queries\nChapter 3: Designing Microservices: The SEED(S) Process\nOnce we have a set of actions and queries, or a Microservice Design Canvas, we can\nChapter 3: Designing Microservices: The SEED(S) Process\nChapter 3: Designing Microservices: The SEED(S) Process\nChapter 3: Designing Microservices: The SEED(S) Process\nThe initial version of the API and service design as captured by an OAS-based\nmodeling work that is necessary for a well-designed API.\n• Client developers who will code against your services (APIs or microservices).\ndesign process of APIs as well as that of microservices.\na lot of confusion on teams trying to adopt microservices architecture.\nteams.\nChapter 3: Designing Microservices: The SEED(S) Process\nAdditionally, we recommend that teams\ndesigning robust microservices.\nChapter 3: Designing Microservices: The SEED(S) Process",
    "keywords": [
      "system design team",
      "team",
      "Microservices Team Topology",
      "microservices team",
      "design team",
      "teams",
      "Microservices",
      "Team Topology",
      "team design",
      "Microservices Operating Model",
      "Team Topology team",
      "API team",
      "design",
      "system design",
      "microservices team template"
    ],
    "concepts": [
      "teams",
      "team",
      "microservices",
      "microservice",
      "designing",
      "design",
      "designed",
      "designs",
      "designers",
      "designate"
    ]
  },
  {
    "chapter_number": 4,
    "title": "Rightsizing Your Microservices:",
    "start_page": 73,
    "end_page": 90,
    "summary": "Rightsizing Your Microservices:\nthe identification of proper microservice boundaries.\nA lot of teams new to microservices stumble at them.\nmodeling, and decomposition of large domains (Domain-Driven Design), explain the\nefficiency benefits of using Event Storming for domain analysis, and close by intro‐\nmicroservices.\neach of our microservices is also small enough?\nsource code of our system is a microservice.\nintroduce crushing levels of complexity that will stop the microservices effort in\nTherefore, services should be\ndesigned in a way that minimizes coordination needs between the teams working on\ndifferent microservices.\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries\nsized microservices.\nyour microservices journey.\nvery granular microservices on day one.\nRather, a large number of microservices is\ngranularity of microservices.\nAvoid Creating Too Many Microservices Too Early\nThe sizing of services in a microservices architecture is most cer‐\nmicroservices over time.\nIf this leads to some of your microservices\nEven if we are starting with just a few microservices, taking it slow, we need some\nreliable methodology to determine how to size microservices.\nDomain-Driven Design and Microservice Boundaries\nAt the onset of figuring out microservices design best practices, Sam Newman intro‐\nDomain-Driven Design and Microservice Boundaries \ncode in a number of services, we would have to release lots of different services at\ncoordination, especially if those services are “owned” by multiple teams, and it\namong microservices practitioners.\nprinciples and arguably do not provide the specific service-sizing guidance needed by\nThe software design methodology known as Domain-Driven Design (DDD) signifi‐\nin his seminal book of the same name, Domain-Driven Design: Tackling Complexity in\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries\nbounded context.\nA Bounded Context defines the range of applicability of each model.\nBounded contexts allow implementation and runtime execution of different parts of\nfully provide a formula for identifying the optimal edges of a bounded context by\nferent meanings in different bounded contexts.\nDomain-Driven Design and Microservice Boundaries \ndifferent meaning in different contexts, and it is OK because we only need to agree on\ncontext of a specific domain model.\nwhich terms change their meaning, we can identify the boundaries of the contexts.\nIn DDD, not all terms that come to mind when discussing a domain model make into\nConcepts in a bounded context that are\nJTBDs that you create for the bounded context.\nthat can be very useful in designing microservice interactions properly: context map‐\nIn DDD, we do not attempt to describe a complex system with a single domain\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries\nbounded contexts.\nwhen used for microservices architectures.\nSprinkling your microservices architecture with shared kernels will introduce many\nmicroservices ecosystem, it’s advised that one team is designated as the primary\nAlternatively, two bounded contexts can engage in what DDD calls an Upstream–\nDomain-Driven Design and Microservice Boundaries \nWhen Upstream modifies their service, they need to ensure that they\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries\nin DDD, such Upstreams are known as open host\nservices.\nlions of customers, but they are able to provide and evolve a useful service by\nIn addition to relation types between domains, context mappings can also differenti‐\nate based on the integration types used between bounded contexts.\nIntegration interfaces between bounded contexts can be synchronous or asynchro‐\nthis interaction pattern, the Upstream can generate events, and Downstream services\nDomain-Driven Design and Microservice Boundaries \nTo wrap up the discussion of Domain-Driven Design’s key concepts, we should\nIn DDD, an aggregate is a collection of related domain objects that can be viewed as a\nIntroduction to Event Storming\nded contexts of their respective domains.\nsize microservices, we just need to become really good in domain-driven analysis; if\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries\nIn the early days of microservices architectures, DDD was so universally proclaimed\nas the one true way to size microservices that the rise of microservices gave a huge\nDon’t get us wrong: there were people using DDD way before microservices, and\nsizing microservices, it was more hype and vaporware than reality.\nTo exacerbate the problem, as we mentioned, DDD is a team sport, and a time-\nin DDD; you also need to sell your business, product, design, etc., teams on partici‐\nbunch of busy people to give you enough time to size your services right!\nproposed a fun, lightweight, and inexpensive process called Event Storming, which is\nIntroduction to Event Storming \nEvent Storming is a highly efficient exercise that helps identify bounded contexts of a\nKey Decision: Use Event Storming Instead of Formal DDD\nUse the more lightweight Event Storming process instead of formal DDD to discover\nThe Event-Storming Process\nred, when possible), all you need to hold a session of Event Storming is a very long\ncessful Event Storming session, it is critical that participants are not only engineers.\nYou can also host virtual Event Storming sessions\nThe process of hosting physical Event Storming sessions starts by purchasing the sup‐\nEvent Storming sessions (see Figure 4-9).\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries\nRequired supplies for an Event Storming session\nDuring Event Storming sessions, broad participation, e.g., from subject-matter\nEvent Storming\nAn Event Storming session that is limited to just software engi‐\nassignment: to write the key events of the domain being analyzed as orange sticky\nIntroduction to Event Storming \nthere should be no coordination of events among participants.\nthey think occur earlier in time to the left, and put the later events more to the right.\nevents in an order that creates something like a “user journey.” In this phase, the team\nIn the third stage, we create what in Event Storming is known as a reverse narrative.\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries\nIntroducing commands to the Event Storming timeline\nBe aware that a lot of commands will have one-to-one relationship with an event.\npeople new to Event Storming.\nStorming, and while some commands may be 1:1 with events, some will not be.\nevents.\nRather, special types of domain entities accept commands and produce events.\nEvent Storming, these entities are called aggregates (yes, the name is inspired by the\nevents, breaking the timeline when needed, such that the commands that go to the\nYou can see an example of this stage of Event Storming\nIntroduction to Event Storming \nAggregates on an Event Storming timeline\nThese clusters are the bounded contexts we were looking for.\n1. Large competitive advantage/large effort: these are the contexts to design and\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries\nEvent Storming facilitator!\n• Phase 1 (~30 min): Discover domain events\n• Phase 4 (~30 min): Identify aggregates/bounded contexts\nBounded contexts are a fantastic starting point for rightsizing microservices.\nto be cautious, however, to not assume that microservice boundaries are synonymous\nwith the bounded contexts from DDD or Event Storming.\nof fact, microservice boundaries cannot be assumed to be constant over time.\nevolve over time and tend to follow an increasing granularity of microservices as the\nIn successful cases of microservices adoption, teams do not start\nwith hundreds of microservices.\nnumber, closely aligned with bounded contexts.\nteams split microservices when they run into coordination depen‐\nabout the granularity of microservices.\nFormula for microservices.\nTo achieve a reasonable sizing of microservices, you should:\n• Start with just a few microservices, possibly using bounded contexts.\n• Keep splitting as your application and services grow, being guided by the needs of\nIn this chapter we addressed a critical question of how to properly size microservices\nWe looked at Domain-Driven Design, a popular methodology for modeling\ncient domain analysis with the Event Storming methodology, and introduced the\nmicroservices.\nChapter 4: Rightsizing Your Microservices: Finding Service Boundaries",
    "keywords": [
      "Event Storming",
      "Finding Service Boundaries",
      "Event Storming sessions",
      "Microservices",
      "microservice boundaries",
      "Service Boundaries",
      "DDD",
      "Event",
      "Storming",
      "Bounded contexts",
      "Boundaries",
      "Event Storming process",
      "Finding Service",
      "Event Storming timeline",
      "events"
    ],
    "concepts": [
      "microservices",
      "microservice",
      "domains",
      "domain",
      "service",
      "services",
      "event",
      "events",
      "ddd",
      "design"
    ]
  },
  {
    "chapter_number": 5,
    "title": "Dealing with the Data",
    "start_page": 91,
    "end_page": 112,
    "summary": "Dealing with the Data\nimportant patterns for microservices data management: delegates, data lakes, Sagas,\nEvent Sourcing, and command query responsibility segregation (CQRS).\nof data management in this space, turning complex, monolithic implementations into\nIndependent Deployability and Data Sharing\nmicroservices.\nmicroservices.\nwhat a typical deployment pipeline looks like in a microservices architecture.\nyour microservices independent, but in the context of data management, the most\ncommon offender is co-ownership of a data space by multiple microservices.\nces by discussing the notion of microservice-embedded data in the following sections.\nChapter 5: Dealing with the Data\nMicroservices Embed Their Data\nIn monolith architectures, sharing of data is a common practice.\nponents co-own data across multiple services as a regular practice.\ndifferent microservices read and modify data from the shared table.\nImagine that a flight-search microservice needs to change a field type of one of the\nwhen we change the data model because of the needs of the flight-search microser‐\nSharing data spaces is a primary killer of independent development and independent\ndeployability is emphasized as a core value and consequently, data sharing is prohibi‐\nas we commonly state the principle: microservices must own (embed) their data.\nMicroservices Embed Their Data \nWhile embedding their own data is a universal rule for microservices, there are some\nimplementing microservices need clarity on how far they should take the notion of\n“microservices must embed their data.” Databases are themselves complex software\nData independence doesn’t mean that\nas services never share the same logical table space and never modify the same data,\nChapter 5: Dealing with the Data\nIn our scenario, depicted in Figure 5-2, we have three services all requiring data from\nExample of a monolithic data management, characterized by data sharing\nfor a microservices architecture, because three services are sharing the data space and\nMicroservices Embed Their Data \nThis way the flight inventory service can be the delegate that hides data\nple services from sharing the same data table.\nPlease note that in this pattern, when several services need access to the same data, we\nUnfortunately, not all data-sharing needs can be addressed this way.\nChapter 5: Dealing with the Data\naccess or modify data across the boundaries of microservices.\ndata.\nthat are also capable of avoiding data sharing.\nspace, let’s first explore various data access patterns we commonly encounter.\nWhen we need read-only access to distributed data with no modification require‐\nThe shared space is usually called a data lake.\ndata, not moving it!\nMicroservices\nData lakes may never be treated as the databases of\nThey are reference data stores.\nStreaming data from microservices into data lakes\nData lakes and shared data indexes can solve for many read-only use cases.\nshould we do when distributed data is not read-only?\nsolution for the cases when we need to modify data in a coordinated fashion across\nMicroservices Embed Their Data \ntransactions span multiple microservices: payments (with loyalty points) processing,\neven in the event of failures.\nChapter 5: Dealing with the Data\ntional data management, ACID transactions are a great example of such thinking.\nthe time, so we design our data storage systems in a way to make them resilient to the\nGiven that microservices embed their data and do not allow code to manipulate data\nMicroservices Embed Their Data \nA transaction distributed across multiple microservices\nChapter 5: Dealing with the Data\nDelegate services, data lakes, and sagas are powerful patterns.\ndata isolation challenges in microservices architectures, but not all of them.\nnext section we will discuss a powerful duo of design patterns: Event Sourcing and\nplete toolset for data management in a microservices environment.\nEvent Sourcing and CQRS\nUp to this point we have discussed some ways to avoid data sharing when using tradi‐\ntional, relational data modeling.\nwhere relational modeling itself falls short of allowing the desired levels of data isola‐\nAt its core, relational data\nfavoring data sharing.\nEvent Sourcing\ning, we should switch to a completely different way of modeling data.\nA data model‐\ning approach that allows avoidance of data sharing, and thus has become popular in\nmicroservices, is known as Event Sourcing.\ngratitude for the advancement of Event Sourcing (and its relationship with CQRS,\nwords, Event Sourcing is an approach to data modeling that is all about storing events\nEvent Sourcing is all about storing facts and any time you have “state” (structural mod‐\nEvent Sourcing and CQRS \nEvent Sourcing in accounting and chess\nany experience with Event Sourcing.\nevent store.\nEvent Sourcing from real life.\nChapter 5: Dealing with the Data\nEvent Sourcing versus relational modeling\nIn conventional data systems such as relational databases, or even the more contem‐\nIn Event Sourcing, we oper‐\nIn Event Sourcing we do not store current\nstate, rather we store facts; the incremental changes of the data.\n(events).\nEvent Sourcing and CQRS \nA relational data model describing the customer manage‐\nExample of a relational data model\nWe can see that the data model could consist of a table storing customers’ contact\nUsing Event Sourcing, we can design the same data model as a sequence of events,\nrelational data model.\nEvent Sourcing in some ways is much simpler\nlate the current state as a derivative of these events.\nExample of an event-sourced data model\nbrute force data segregation here, all we would need to do is say each type of event is\nowned by a different microservice, and voila, we could do that and avoid data shar‐\nmicroservice and “customer info entered” would be an event that very naturally\nWhat does an event look like?\nlet’s dig a little bit deeper into what data modeling and data management looks like in\nEvent Sourcing.\nsomething you calculate off of these events—a state is a function of events.\nWell, events are\nIf we look at the “shape” of an event data structure, all it needs to have\nFirst, the event needs some kind of unique identifier.\nIt also needs to have an event type, so we\n\"data\" : {\nEvent Sourcing and CQRS \nevents.\nWe run what in Event Sourcing is called projections.\ngive us state based on events, and they’re also fairly simple.\nevent to calculate the new state.\nfunction priceUp(state, event) {\nstate.increasePrice(event.amount)\nthe projection functions for all relevant events, like the following:\nfunction priceUp(state, event) {\nstate.increasePrice(event.amount)\nfunction priceDown(state, event) {\nstate.decreasePrice(event.amount)\nrent state is the left fold of the events that occurred until the current time.\nthrough using Event Sourcing you can calculate not just the current state but the state\nDepending on the event store implementation, it is common to snapshot intermedi‐\nIn Event Sourcing, the saved projections are usually called rolling snapshots.\nHaving acquired an understanding and appreciation of Event Sourcing, let’s learn\nWhat would the event store itself look like?\nEvent Sourcing and CQRS \nEvent Store\nEvent stores can be relatively simple systems.\nService (S3) buckets, or any database storage that can reliably store a sequence of data\nThe interface of an event store needs to support three basic\nevent duplication leading to data corruption.\nTo implement robust projections, Event Sourcing systems often use a complementary\nProjections for advanced event-sourced systems are typically built using the Com‐\nthe way we query systems and the way we store data do not have to be the same.\nEvent Sourcing should only\nmized for querying the data any way they need.\nThe big win with using Event Sourcing and CQRS is that they allow us to design very\nWith Event Sourcing, we can create microser‐\nuse of Event Sourcing and CQRS can take us to the next level of autonomous granu‐\nEvent Sourcing and CQRS Should Not Be Abused as a Cure-All Solution\nBe careful not to overuse Event Sourcing and CQRS.\nThey should not be used as the one and only data\nEvent Sourcing and CQRS \nEvent Sourcing and CQRS can help you avoid data sharing between microservices in\nsophisticated cases where you require data joins across service boundaries, but they\nthe delegate service we described in this chapter, before you resort to Event Sourcing,\nbeyond just helping with loose data coupling for the data-embedding needs of\nmicroservices.\nEvent Sourcing and CQRS Beyond Microservices\nEvent Sourcing and CQRS can certainly be invaluable in avoiding data sharing and\nEvent Sourcing and CQRS are\npowerful data modeling tools that can benefit a variety of systems.\nConsider Event Sourcing and CQRS in relation to the consistency, availability, and\nHaving a single view of the latest state of the data\nThe CAP theorem tells us that a single system, with data sharing\nauthoritative sources, so we can always re-index from the event store, if need be.\nThe second major benefit of the Event Sourcing and CQRS approach is related to\nWhen we use a relational data model, we do in-place updates.\nserved and we can see what the value of customer data was at any time in the past, as\nSo, how is logging different from Event\nIn Event Sourcing, the “state” is calculated from the events, so the\nWhen your reliable log of events is your source of\ntruth, you are using Event Sourcing as your data modeling approach.\ndata isolation and the principle of embedding data into corresponding microservices.\npendent deployability, can lead us to significant data management challenges if we\napproach them with conventional data modeling solutions, the ones designed for\nto data modeling, which is distinctly different from conventional, relational\ning and CQRS, even beyond microservices needs.",
    "keywords": [
      "Event Sourcing",
      "Data",
      "Event",
      "Sourcing",
      "microservices",
      "Event Sourcing systems",
      "event store",
      "Events",
      "Sourcing and CQRS",
      "Data Sharing",
      "CQRS",
      "state",
      "data model",
      "system",
      "data modeling"
    ],
    "concepts": [
      "data",
      "event",
      "events",
      "microservice",
      "microservices need",
      "state",
      "states",
      "stated",
      "services",
      "service"
    ]
  },
  {
    "chapter_number": 6,
    "title": "Building an Infrastructure Pipeline",
    "start_page": 113,
    "end_page": 152,
    "summary": "Building an Infrastructure Pipeline\nIn this chapter, we’ll establish the foundation for our infrastructure work.\nautomate infrastructure changes.\nIn order to reduce the work that our microservices teams need to do, we’ll need to\nWe’ll need to make it\ncheap and easy to create a new environment and provide the right kit to make relea‐\ning the way you make changes to the infrastructure itself.\ncost of building and changing the infrastructure, we’ll be able to deliver new environ‐\nWe’ll be able to make infrastructure\ncan use to build a microservices infrastructure.\nfile for the infrastructure code, a pipeline for testing and building (see Figure 6-1),\nChapter 6: Building an Infrastructure Pipeline\nTo make this happen, we’ll use three concepts from the DevOps world in our infra‐\nAn object is immutable if it can’t be changed after it’s created.\nIntroducing new servers or making changes to environment states\nInfrastructure components must not be changed after they’ve been created.\nSo we’ll need to make some additional decisions to make this\nOtherwise, we’ll end up never making infrastructure changes because\nThe first decision we’ll make is one we’ve alluded\nwe’ll still need a way of defining all of our infrastructure with a manageable set of\nInfrastructure as Code\nstructure code becomes a way of managing the infrastructure state.\nmanaging the way we write, test and deploy our infrastructure code.\nChapter 6: Building an Infrastructure Pipeline\nAll infrastructure changes should be made in managed code files.\nTo get going with an IaC approach, we’ll need a tool that will allow us to define the\nchanges we want to make as machine-readable code files.\nTerraform as the tool for infrastructure changes, so let’s start by documenting that\nKey Decision: Use Terraform for Infrastructure Changes\nWe’ll use HashiCorp’s Terraform tool to manage and apply changes to the platform\nTerraform isn’t the only tool that can help us with infrastructure changes and there\nWe’ve chosen to use Terraform\ndeclare a target state for the infrastructure and Terraform will do the hard work of\nTerraform also embraces the principle of immutable infrastructure that we decided to\nWhen we apply our code, Terraform\nTo make that magic happen, Terraform needs to keep track of states.\nImmutability and IaC make our infrastructure changes more predictable.\nchange because of all the validation work we’d need to do.\neffort right before making a production change, we’ll continuously integrate our\nWe’ll also continuously test that our changes work and\nChapter 6: Building an Infrastructure Pipeline\nThat’s why we’ll be using a special kind of tool called a pipeline.\nKey Decision: Apply System Changes with a CI/CD Pipeline\nAll changes must be applied through an automated pipeline and/or tool.\nWe’ll be using a pipeline for all changes—not just infrastructure ones.\nwe’ll focus on the pipeline for our infrastructure changes.\nwe’ve decided to use GitHub Actions as our CI/CD pipeline tool.\nKey Decision: Use GitHub Actions for CI/CD Pipelines\nTeams should use GitHub Actions to implement CI/CD pipelines for infrastructure\nActions because we plan to use GitHub to manage our code.\nBy the end of this chapter, we will have built a CI/CD pipeline in GitHub Actions.\nWe’ll also configure the pipeline to handle Terraform code and make changes to a\nWhen you write application code, you need a development environment with tools\nIn this section, we’ll set up both a local environment and a cloud-hosted\nThe first thing we’ll need is a way to manage and release our code.\nto use GitHub for our model because it’s become a very popular place to share code.\nThat’s useful for our implementation, because we’ll be sharing a lot of code and con‐\nKey Decision: Use GitHub for Code Management\nAll code will be managed using the Git version control system and hosted in GitHub. In order to work with our examples, you’ll need to register for a GitHub account and\nIn addition to the Git client, you’ll need a GitHub account so you can manage your\ncode and configure your own CI/CD pipelines.\nWe’ll be using Git and GitHub to manage our microservices code.\nprinciple of IaC, we’ll also be using these tools to manage infrastructure code.\nChapter 6: Building an Infrastructure Pipeline\nAs we mentioned earlier, we’ll be using Terraform to manage and apply our infra‐\nactually need to install Terraform on your workstation.\nyou’ll need a local installation to test code before you commit it to the pipeline.\nworthwhile installing Terraform in your local environment.\nAt the time of writing, Terraform is available to run on the following platforms:\nWe’ll be using Terraform to manage infrastructure resources in a cloud platform.\nwe’ll be using AWS and what we need to do to get started with it.\nEarlier, we made a decision to use a cloud-hosted infrastructure.\nvein, we’ve decided to use AWS and its services for our examples, primarily because it\nWe’ll use AWS as the cloud platform for microservices.\nSince we’ve decided to use AWS, you will need to have an AWS account to follow\naccount so that the tools we’re setting up will have access to your AWS instance.\nSetting Up an AWS Operations Account\nBy the end of this chapter, we’ll have a pipeline that can deploy infrastructure into\nbility, we should never have to manage our AWS infrastructure by making changes\nBut, to start off with, we’ll need to perform a few steps\ncredentials and permissions to allow our tools to work with our AWS objects.\nWe’ll need to create a special user that represents\nChapter 6: Building an Infrastructure Pipeline\nWe’ll use this\nuser identity whenever we are making calls from our CI/CD pipeline platform.\nmentioned earlier, we’ll be using Terraform as our primary IaC tool.\nin this section to create a Terraform user in AWS that will allow us to make the kinds\nof changes we’ll need for our microservices environment.\nOur operator account will need a lot of permissions to do work in AWS on our\nChapter 6: Building an Infrastructure Pipeline\nBefore we do anything else, we’ll need to make a note of our new user’s keys.\nWe have now created a user called ops-account with permission to make IAM\nneed to do is configure the CLI to use the ops user we’ve just created.\naccount and later we’ll be using Terraform to configure changes via the AWS APIs. But, we’ll need to make some more changes before Terraform can make AWS API\nFor that we’ll use the AWS CLI.\nUsing the CLI makes it a lot easier for us to describe the changes you need to make.\nCLI, the first thing we’ll need to do is install it into our local working environment.\nChapter 6: Building an Infrastructure Pipeline\nRun the aws configure command as shown in Example 6-1.\n\"Arn\": \"arn:aws:iam::842218941332:user/ops-account\",\nWhen we created our ops-account user we attached an IAM policy to it that only\npermissions than that to manage the AWS resources we’ll need for our infrastructure\nIn this section, we’ll use the AWS command-line tool to create and attach addi‐\nThe first thing we’ll do is make the ops-account user part of a new group called Ops-\nThat way we’ll be able to assign new users to the group if we want them to\nUse the following command to create a new group called\n$ aws iam create-group --group-name Ops-Accounts\nIf this is successful, the AWS CLI will display the group that has been created:\nThe permissions we’ll be attaching will let our user create and\nchange AWS resources.\nRun the following command to attach all the policies we’ll need to the Ops-Accounts\nChapter 6: Building an Infrastructure Pipeline\nIn addition to the out-of-the-box policies that AWS provides, we’ll also need some\nwe need, so we’ll need to create our own custom policy and attach it to our user\nTo do this, create a file called custom-eks-policy.json and populate it with the code in\nNow, run the following command to create a new policy named EKS-Management\n$ aws iam create-policy --policy-name EKS-Management\\\nicy you’ve just created will be unique to you and your AWS\ncreate AWS infrastructure resources for us.\nWe’ll be using this user account when we\nwrite our Terraform code and when we configure the infrastructure pipeline.\nsure you keep the access key and secret somewhere handy (and safe) as we’ll need it\npipeline: the creation of an AWS S3 storage bucket for Terraform to store state.\nChapter 6: Building an Infrastructure Pipeline\nCreating an S3 Backend for Terraform\nTerraform is powerful because it allows us to declare what an infrastructure should\nTerraform\nworks its magic by making the right changes to an environment to make it look the\nBy default, Terraform will keep this state file in your local filesystem.\nInstead, we’ll use the AWS S3 service to store the Terraform state file.\nTerraform\nAll we’ll need to\ncase, Terraform will be storing environment state as JSON objects.\nTo create a bucket, you’ll need to give it a unique name and pick the region that it\nured the AWS CLI and we suggest that you use the same region for the S3 bucket.\n> --region {YOUR_AWS_REGION} --create-bucket-configuration \\\nbecause we don’t want just anyone to be able to see and change our Terraform state\nWith this final step complete, we now have an AWS user called ops-account config‐\nstore objects in a special S3 bucket we’ve created just for managing Terraform state.\nThis should be the last time we make manual operator changes to our AWS instance;\nfrom here on out we’ll only make changes through code and with an automated\nChapter 6: Building an Infrastructure Pipeline\nInstead, we’ll have a stable declarative definition of the infrastructure for our services.\ntheir own environments to perform testing, make changes, and release services into\nWe won’t be implementing any of the actual AWS infrastructure in this\n• A GitHub-hosted Git repository for a sandbox testing environment\n• A GitHub Actions CI/CD pipeline that can create a sandbox environment\nWe’ll build it out in the\nwe’ll use all of these assets to build a test environment for the microservices that we’ll\nGitHub to manage our infrastructure code.\nWe’re going to use both of those tools to create a new repository for our sandbox\nstill keeping the pipeline configuration and code together for easier management.\nEach environment’s code and pipeline will be managed independently in its own code\nWe’ll use GitHub’s browser-based interface to create the sandbox repository.\nuse the web-based interface to create our new repository.\nCreate a GitHub sandbox repository\nIt’s important that we ask GitHub to add a .gitignore for Terraform to the module\nbecause it will make sure we don’t accidentally commit Terraform’s hidden working\nChapter 6: Building an Infrastructure Pipeline\nThat’s all we need to do with GitHub for now.\nwe can begin work on the Terraform code.\nWe mentioned earlier that we’ll be using Terraform as our tool of choice for declara‐\nTerraform files are configured in a data format called HCL, which was invented by\nHashiCorp (the company that created Terraform).\nIn addition to understanding HCL, it’s useful to understand four of the key Terraform\nTerraform needs to maintain a state file so that it knows what kinds of changes to\nmake to the infrastructure environment.\nWe’ll be using an AWS S3\nTerraform does the work of making the changes to bring the resource to that\nWe’ll be using Terraform’s AWS provider for most of our work.\nthing about Terraform is that you can use it for lots of different cloud platforms\nOur next step is to write some Terraform code that will help us build a sandbox envi‐\nOur goal in this chapter is to set up the tooling and infrastructure for our environ‐\nment build, so we won’t be writing a complete Terraform file that defines our infra‐\nFor now, we’ll need to create a simple starter file to\nThe Terraform CLI tool works by looking for files it recognizes in the working direc‐\nment and we’ll need to create a Terraform main.tf file that will describe its target state.\nWe’ve already created a Git repository called env-sandox for the sandbox environ‐\nment, so that’s the directory we’ll use for the Terraform code.\nating a new file called main.tf in the local sandbox Git repository.\n{YOUR_AWS_REGION} with the S3 bucket name you created earlier\nChapter 6: Building an Infrastructure Pipeline\nterraform {\nindicating where we’ll be adding details for the infrastructure.\njust want to test the scaffolding of our Terraform file.\nWith our first Terraform code file written, we’re ready to try running some Terraform\ndry run of the changes that Terraform would run against your provider.\nof Terraform available in your working environment.\nThe fmt command is a formatter that will examine your HCL file and make changes\ndo that we’ll need to install the providers we’re using; otherwise Terraform will com‐\nany changes that are required for your infrastructure.\nIf you ever set or change modules or backend configuration for Terraform,\nFinally, we can run a command called plan to see what changes Terraform would\nmake to create the environment we’ve specified.\nwill be run when the code is applied, but it doesn’t actually make any changes.\nChapter 6: Building an Infrastructure Pipeline\nsyntactically valid Terraform file to start building our sandbox environment.\nthe pipeline that we’ll use to automatically apply it.\nIn this section we’ll set up an automated CI/CD pipeline that will automatically apply\nthe Terraform file that we’ve just created.\nTo configure the pipeline activities, we’ll be\nGitHub Actions is that we can put our pipeline configuration in the same place as our\ninfrastructure code.\nThe easiest way to use GitHub Actions is to configure it through the browser inter‐\nearlier in GitHub. Our plan is to create resources in the AWS account that we created earlier in this\nThus, we’ll need to make sure that GitHub is able to use the AWS access key\ning, we’ll just use GitHub’s built-in secrets storage function.\nSelect “Add a new secret” and create a secret called AWS_ACCESS_KEY_ID.\nRepeat the process and create a secret named AWS_SECRET_ACCESS_KEY\nChapter 6: Building an Infrastructure Pipeline\nA workflow is the set of steps that we want to run whenever a pipeline is triggered.\nFor our microservices infrastructure pipeline, we’ll want a workflow that validates\nTerraform files and then applies them to our sandbox environment.\nto testing and applying infrastructure changes, we’ll need to add a few steps before\nand after applying our Terraform files.\nThe workflow will need to start with a trigger that lets GitHub know when the work‐\nwe’ll use Git’s tag mechanism as the trigger for our infrastructure builds.\nWhen our pipeline workflow is triggered it will need to operate on the Terraform files\nBut, we’ll need some setup steps to prepare\nFirst, we’ll install Terraform and AWS just like we did in our\nAlthough we are running this in GitHub Actions, the actual build\ntakes place in a virtual machine, so we’ll also need to grab a copy of the code from our\nFinally, when the changes are applied to our sandbox environment, we’ll have a\nInfrastructure pipeline steps\nWe’ll be defining the steps of the pipeline using the YAML language and the set of\nworkflow commands in GitHub Actions.\nCreate a GitHub Actions workflow\nGitHub Actions provides you with templates you can use to quickly get started with a\nHub keeps the Actions files in a hidden directory called /.github/workflows.\ncreate new YAML files to define new GitHub Action workflows.\nThe first thing we’ll do is configure a trigger for the workflow and set up a container\nenvironment to do the infrastructure build.\nChapter 6: Building an Infrastructure Pipeline\nwe mentioned earlier, we’ll use a simple trigger based on Git’s tagging mechanism.\nWe’ll configure our pipeline so that it runs whenever infrastructure is tagged with a\nWe’ll use\nWe’ve configured our workflow to run when a new tag that matches\nSo the first step we’ve defined is to check out our Terraform code\nstart working with Terraform, but before we can do that we need to get the environ‐\nWhen we set up our local infrastructure development environment, we needed to\ninstall the Git, AWS, and Terraform command-line tools.\nWe’ll need to do something\nsimilar in our build environment, but since we know the specific operations we’ll be\nThe good news is that we get Git for free when we use GitHub Actions, so we won’t\nAction for Terraform, so we won’t need to worry about installing the Terraform cli‐\nEarlier in this chapter we used the AWS CLI to make changes to our AWS account.\nour pipeline environment, however, we want to use Terraform to make changes.\nfact, we don’t want to make any changes to the environment beyond what we’ve speci‐\nSo we won’t need to install the AWS CLI.\nAll of this tells us that we don’t need to install any dependencies to make a pipeline\nthat can create AWS resources for us.\nin the next chapter, we’ll find out that our infrastructure needs some special depen‐\nChapter 6: Building an Infrastructure Pipeline\nSpecifically, we’ll be installing an AWS authenticator tool and an installer for the Istio\nThe AWS authenticator is a command-line tool that other tools can use\nwe are working with Kubernetes and need to configure access to an AWS-hosted\nter; for now we just need to make sure we’ve installed the CLI tool.\nAdd the code in Example 6-5 to your workflow file to set up those dependencies in\nWe’ve added instructions to install the AWS IAM\nflow will be created at the start of every pipeline run and destroyed\nThe last part of our YAML code uses HashiCorp’s Terraform setup action.\nApplying Terraform files\nTerraform workflow\nChapter 6: Building an Infrastructure Pipeline\nAs you can see from your YAML, we’re using the run action to call the Terraform CLI\nAWS infrastructure.\nWhen a GitHub Actions workflow completes, the VM that we used for our build is\nIn the next chapter, we’ll be setting up a Kubernetes cluster on AWS.\ndo that, you need a lot of connection and authentication details, which we’ll make\nThis action uploads a file called kubeconfig from the local working directory of the\nbuild environment to your GitHub Actions repository.\nso we’ll need to create that file in the next chapter when we get into the details of\nGitHub manages the workflow files the same way it manages\nSo, we’ll need to commit our changes to save them.\nCommitting a change in GitHub Actions\nstep for your Terraform code.\nChapter 6: Building an Infrastructure Pipeline\nTo test the pipeline that we’ve created, we’ll need to fire the trigger for the job we\nIn our case, we need to create a Git tag in our repository with a label that\nBut since we’ll be doing most of our work outside GitHub on our\nlocal workstation, we’ll create the tag there instead.\nsomething like Example 6-8 indicating that we’ve pulled the new .github/workflows/\nNow that we are up to date with the GitHub-hosted repository, we can create a tag.\nSince this is just a test, we’ll label our release “v0.1.” Use the git tag command as\nIn order to trigger our workflow, we’ll need to push this tag to our\nHub Actions, so all we need to do now is check to make sure it has run successfully.\nChapter 6: Building an Infrastructure Pipeline\nWith our pipeline successfully tested, we’ve finished setting up the tooling we need to\nWe installed and used Terraform as our tool for\nGitHub-based code repository to manage that code.\nsteps of making an infrastructure change.\nWe created and edited a Terraform file, tes‐\nimmutable infrastructure development and we’ll be using it often in the next chapter",
    "keywords": [
      "AWS",
      "Terraform",
      "Infrastructure Pipeline",
      "Infrastructure",
      "’ll",
      "Pipeline",
      "AWS CLI",
      "aws iam",
      "GitHub Actions",
      "Terraform code",
      "AWS infrastructure",
      "GitHub",
      "Terraform CLI tool",
      "code",
      "Actions"
    ],
    "concepts": [
      "terraform",
      "aws",
      "infrastructure",
      "infrastructures",
      "github",
      "changes",
      "changing",
      "change",
      "changed",
      "pipeline"
    ]
  },
  {
    "chapter_number": 7,
    "title": "Building a Microservices Infrastructure",
    "start_page": 153,
    "end_page": 194,
    "summary": "infrastructure for our microservices system will be defined in code and we’ll be able\nBut we’ll need a lot of supporting infrastructure to make all\nfocus on designing and writing Terraform code to create a working network, an AWS\nThe good news is, you don’t need to be a network or Kubernetes\nMicroservices need to be run on a network.\nwe’ll need to tailor our network design accordingly, and create a virtual network\nAWS network resources and configure those accordingly.\nIn AWS, a virtual private cloud (VPC) is the parent object for a virtual network.\nWe’ll be creating and configuring a VPC as part of our network design.\nWe’ll be creating a total of four subnets as part of our network configuration.\nIn addition to creating the VPC and subnet objects, we’ll be defining objects that\ncomplexity comes from the needs of the Kubernetes service running on top of it.\ntogether a working Kubernetes infrastructure hosted on AWS.\nIn our implementation, we’ll be using an AWS managed service for Kubernetes called\nWe will use AWS EKS as a managed service for our Kubernetes cluster.\ntions teams if the real world has drifted from the state defined in Git. Argo CD is a GitOps tool that facilitates the work of deploying Kubernetes applica‐\nBy the end of this chapter, we’ll have created a sandbox environment with an Argo\nCD server installed on top of an AWS managed Kubernetes cluster, running on an\nAWS VPC network.\nIn Chapter 6 we established a decision to use Terraform to write the code that defines\nIn this section, we’ll break our infrastructure design into discrete Terraform modules\nWe’ll start by setting up the tools you’ll need in your infrastructure develop‐\n• Git, Terraform, and AWS CLI tools installed in your workstation\ninstalling the Kubernetes service, we’ll need a way to test and interact with the Kuber‐\nmodules that will define the infrastructure.\nSince we’re taking the IaC approach, we’ll need to apply good code practices to our\nBut with Terraform we’ll be able to apply three essential coding practices that will\nUse modules\nTerraform’s built-in support for modules of infrastructure code will help us in using\nWe’ll be able to maintain our infrastructure code as a set of\nWe’ll build modules for each of the architecturally\nOnce we have our reusable modules in place, we’ll be able\nto implement another set of Terraform files that use them.\nferent Terraform file for each environment that we want to create without repeating\nReusing a network module\nWe can start by creating a simple module that defines a basic network\nThe infrastructure code we are writing in this chapter uses Terraform’s module struc‐\nEach module will have its own directory and contain variables.tf, main.tf, and\nmore about these modules in the Terraform documentation.\nWe’re going to create two modules for our microservices infrastructure.\ncreate an AWS networking module that contains a declarative configuration of our\nWe’ll also create a Kubernetes module that defines an\nAWS-based managed Kubernetes configuration for our environments.\nto use both of these modules to create our sandbox environment.\nIn Chapter 6, we created a GitHub code repository for the sandbox environment code\nalso create a new repository for each module we write.\nTo get started, let’s create the repositories for all the modules we’ll be writing in this\nmodule-aws-network\nA Terraform module that creates the network\nmodule-aws-kubernetes\nA Terraform module that sets up EKS\nA Terraform module that installs Argo CD into a cluster\nWith our three GitHub module repositories created and ready to be populated, we\nThe Network Module\nus to start by defining the network module.\nwork module that will support a specific Kubernetes and microservices architecture\nBecause it’s a module, we’ll be writing input, main, and output code—\nwe’re done, we’ll be able to use this module to easily provision a network environ‐\nWe’ll be writing the network infrastructure code in the module-aws-network GitHub\nWe’ll be creating and editing Terraform files in the\nA completed listing for this AWS network module is available in\nNetwork module outputs\nLet’s start by defining the resources that we expect the networking module to pro‐\nWe’ll do this by creating a Terraform file called output.tf in the root directory of\nmodule-aws-network, as in Example 7-1.\nmodule-aws-network/output.tf\nvalue = aws_vpc.main.id\naws_subnet.public-subnet-a.id,\naws_subnet.public-subnet-b.id,\naws_subnet.private-subnet-a.id,\naws_subnet.private-subnet-b.id]\nBased on the Terraform module output file, we can see that the network module cre‐\nWithin that network, our module will also create four logical subnets—these are the\nfor our Kubernetes cluster setup and eventually we’ll deploy our microservices into\nNetwork module main configuration\nIn a Terraform module,\nwe’ll be creating and editing a file named main.tf in the root directory of the module-\naws-network repository.\ncomplete source code listing for this module at this book’s GitHub\nWe’ll start our module implementation by creating an AWS VPC resource.\nprovides us with a special resource for defining AWS VPCs, so we’ll just need to fill in\nWhen we create a resource in Terraform,\nWhen we apply these changes, Terraform will make an AWS API call and create the\nCreate a file called main.tf in the root of your network module’s repository and add\nthe Terraform code in Example 7-2 to the main.tf file to define a new AWS VPC\nmodules-aws-network/main.tf\nresource \"aws_vpc\" \"main\" {\nThe network module starts with a declaration that it is using the AWS provider.\nthe libraries it will need in order to communicate with the AWS API and create\nAfter the local variable declaration, you’ll find the code for creating a new AWS VPC.\nthis cluster as a target for our Kubernetes cluster (which we’ll define in “Defining the\nand we’ll define their values later when we use this module as part of our sandbox\nKubernetes service (EKS) to run our workload.\nwe’ll need to have subnets defined in two different “availability zones.” In AWS, an\nbecause even though the AWS resources are virtual, they’re still running on a com‐\nAWS subnet design\nthis case, we’ll put public-subnet-a and private-subnet-a in data.aws.availabil\nFinally, we’ll add a name tag so that we can easily find our network resources through\nWe’ll also need to add some EKS tags to the subnet\nresources so that our AWS Kubernetes service will know which subnets we are using\nWe’ll tag our public subnets with an elb role so that EKS\nAdd the Terraform code in Example 7-3 to the end of your main.tf file in order to\nmodules-aws-network/main.tf (subnets)\nresource \"aws_subnet\" \"public-subnet-a\" {\nresource \"aws_subnet\" \"public-subnet-b\" {\nresource \"aws_subnet\" \"private-subnet-a\" {\nresource \"aws_subnet\" \"private-subnet-b\" {\nIn the network module, we’re using the aws_availa\nthe network rules that AWS will need to manage traffic through them.\nnetwork design, we’ll need to implement a set of routing tables that define what traffic\nWe’ll start by defining the routing rules for our two public subnets: public-subnet-a\nTo make these subnets accessible on the internet, we’ll need to\nThis is an AWS network\na resource definition for the gateway, so we’ll use that and tie it to our VPC with the\nOnce we’ve added the internet gateway, we’ll need to define routing rules that let AWS\nan aws_route_table resource that allows all traffic from the internet (which we’ll\nAdd the Terraform code in Example 7-4 to main.tf to define routing instructions for\nmodules-aws-network/main.tf (public routes)\nThat’s because we’ll need to define a route\nFor that kind of route to work, we’ll need a way for nodes in our private subnet to talk\nIn AWS, we’ll need to\nmodules-aws-network/main.tf (NAT gateway)\nIn addition to the NAT gateway we’ve created, we’ll need to define routes for our pri‐\nAdd the Terraform code in Example 7-6 to main.tf to complete the defi‐\nmodules/network/main.tf (private routes)\nwe’ll have an AWS software-defined network that is ready for Kubernetes and our\nBut, before we can use it, we’ll need to define all of the input variables\nthat this module needs.\nTerraform modules require us to identify all of the input variables we’ll be using in a\nNetwork module variables\nCreate a file in the root folder of the network module called variables.tf.\nraform code in Example 7-7 to variables.tf to define the inputs for the module.\nmodules/network/variables.tf\nWe’ll give the module values for\nthose variables when we use it to create an environment.\nable in your Terraform module.\nThe Terraform code for our network module is now complete.\nWith the code written, we’ll be testing the network module by creating a sandbox\nenvironment network, but before we use the module we should make sure we haven’t\nUse the following Terraform command while you are in your module’s working direc‐\nmodule-aws-network$ terraform fmt\nNext, run terraform init so that Terraform can install the AWS provider libraries.\nmodule-aws-network$ terraform init\nmodule-aws-network$ terraform validate\nmodule-aws-network$ git add .\nmodule-aws-network$ git commit -m \"network module created\"\n[master ddb7e41] network module created\nmodule-aws-network$ git push\nOur Terraform-based network module is now complete and available for use.\na main.tf file that declaratively defines the resources for our network design.\nhas an outputs.tf file that defines the significant resources that we’ve created in the\nmodule.\nNow we can use the module to create a real network in our sandbox\nThe nice thing about using Terraform modules is that we can create our environ‐\nvariables.tf file, any environment that we create with the module we’ve defined will\nBut to apply the module we’ve defined and create a new environment, we’ll need to\ncall it from a Terraform file that defines values for the module’s variables.\nwe’ll create a sandbox environment that demonstrates a practical example of using a\nTerraform module.\nIn order to use the network module that we’ve created, we’ll use a special Terraform\nresource called module.\nIt allows us to reference a Terraform module that we’ve cre‐\nIn our case, we want Terraform to retrieve the network module from a GitHub repos‐\nFor example, a source value of \"github.com/implementing-microservices/module-\naws-network\" references our example network module.\nmicroservices/module-aws-network\nWhen you have the path for your network module ready, open the main.tf file for the\nthe source value with the path of your network module’s GitHub repository.\nmodule \"aws-network\" {\nsource = \"github.com/{YOUR_NETWORK_MODULE_REPO_PATH}\"\nneed to check to make sure that the Terraform code we’ve written will work.\nIf you need to debug the networking module and end up making\ncode changes, you may need to run the following command in\nwork module from GitHub. If the code is valid, we can get a plan to validate the changes that Terraform will make\nYou can test that the VPC has been successfully created by making an AWS CLI call.\npened, it indicates that you now have an AWS network running and ready to use.\nnow time to start writing the module for the Kubernetes service.\nThe Kubernetes Module\nTo build our Kubernetes module, we’ll follow the same steps that we did to build our\nnetwork module.\nWe’ll start by defining a set of output variables that define what the\nmodule will produce, then we’ll write the code that declaratively defines the configu‐\nearlier in this chapter, we are managing each of infrastructure modules in it’s own\nfor our Kubernetes module if you haven’t done so already.\nrunning as quickly as possible, we’ll use a managed service that will hide some of the\nSince we are running on AWS in our\nAn EKS cluster contains two parts: a control plane that hosts the Kubernetes system\norder to configure EKS, we’ll need to provide parameters for both of these areas.\nWhen the module is finished running, we can return an EKS cluster identifier so that\nworking in the module-aws-kubernetes GitHub repository that you created earlier,\nA completed listing for this Kubernetes module is available in this\nKubernetes module outputs\nWe’ll start by declaring the outputs that our module provides.\nCreate a Terraform file\ncalled outputs.tf in the root directory of the module-aws-kubernets repository and\nmodule-aws-kubernetes/outputs.tf\nvalue = aws_eks_cluster.ms-up-running.id\nvalue = aws_eks_cluster.ms-up-running.name\nvalue = aws_eks_cluster.ms-up-running.certificate_authority.0.data\nvalue = aws_eks_cluster.ms-up-running.endpoint\nvalue = aws_eks_node_group.ms-node-group.id\nThe main value we’re returning is the identifier for the EKS cluster that we’ll be creat‐\nple, we’ll need the endpoint and certificate data when we install the Argo CD server\nbefore, we’ll build the module’s main Terraform file in parts before we test it and\nTo start, create a Terraform file called main.tf in the root directory of your Kubernetes\nmodule and add an AWS provider definition, as in Example 7-10.\nmodule-aws-kubernetes/main.tf\nBut EKS will need to create and modify AWS resources on\nSo we’ll need to set up permissions in our AWS account so\nWe’ll need to define policies and security rules \nTerraform code in Example 7-11 to your main.tf file to define a new cluster access\nmodule-aws-kubernetes/main.tf (cluster access management)\nresource \"aws_iam_role\" \"ms-cluster\" {\nresource \"aws_iam_role_policy_attachment\" \"ms-cluster-AmazonEKSClusterPolicy\" {\ndefined by AWS for us and gives the EKS the permissions it needs to create VMs and\nmake network changes as part of its Kubernetes management work.\nvariable throughout the module.\nNow that the cluster service’s role and policy are defined, add the code in\nExample 7-12 to your module’s main.tf file to define a network security policy for the\nmodule-aws-kubernetes/main.tf (network security policy)\nresource \"aws_security_group\" \"ms-cluster\" {\nThe Terraform code we’ve just written defines an egress rule that allows unre‐\nWhen we use this module, we can give it the ID\nof the VPC that our networking module has created.\nthe declaration for the cluster itself to the main.tf Terraform file (see Example 7-13).\nmodule-aws-kubernetes/main.tf (cluster definition)\nresource \"aws_eks_cluster\" \"ms-up-running\" {\naws_iam_role_policy_attachment.ms-cluster-AmazonEKSClusterPolicy\ncreated earlier in the networking module, and we’ll be able to pass them into this\nKubernetes module as a variable.\nWhen AWS creates an EKS cluster, it automatically sets up all of the management\ncomponents that we need to run our Kubernetes cluster.\nFor our configuration, we’ll define a managed EKS node group and let\nAWS provision resources and interact with the Kubernetes system for us.\nmanaged node group running, we’ll still need to define a few important configuration\nJust like we did for our cluster, we’ll begin the node configuration by defining a role\nthe Kubernetes module’s main.tf file.\nmodule-aws-kubernetes/main.tf (node group IAM)\nresource \"aws_iam_role\" \"ms-node\" {\nresource \"aws_iam_role_policy_attachment\" \"ms-node-AmazonEKSWorkerNodePolicy\" {\nresource \"aws_iam_role_policy_attachment\" \"ms-node-ContainerRegistryReadOnly\" {\nWe could hardcode all of these parameters in our module, but instead we’ll use input\nto use the same Kubernetes module to create different kinds of environments.\nAdd the Terraform code in Example 7-15 to the end of the module’s main.tf file to\nmodule-aws-kubernetes/main.tf (node group)\nresource \"aws_eks_node_group\" \"ms-node-group\" {\ncluster_name    = aws_eks_cluster.ms-up-running.name\nenough here to be able to call this module from our sandbox environment and\ninstantiate a running Kubernetes cluster on the AWS EKS service.\nAppend the code in Example 7-16 to your module’s main.tf file.\nmodule-aws-kubernetes/main.tf (generate kubeconfig)\n${aws_eks_cluster.ms-up-running.certificate_authority.0.data}\"\nserver: ${aws_eks_cluster.ms-up-running.endpoint}\nname: ${aws_eks_cluster.ms-up-running.arn}\ncluster: ${aws_eks_cluster.ms-up-running.arn}\nuser: ${aws_eks_cluster.ms-up-running.arn}\nname: ${aws_eks_cluster.ms-up-running.arn}\ncurrent-context: ${aws_eks_cluster.ms-up-running.arn}\n- name: ${aws_eks_cluster.ms-up-running.arn}\n- \"${aws_eks_cluster.ms-up-running.name}\"\nthe EKS resources that we created in the module.\nWhen Terraform runs this block of code, it will create a kubeconfig file in a local\nWe’ll be able to use that file to connect to the Kubernetes environment\nWe’re almost done writing our Kubernetes service module; all that’s left is to define\nKubernetes module variables\nTo declare the variables for our Kubernetes module, create a file called variables.tf in\nyour module-aws-kubernetes repository and add the code in Example 7-17.\nmodule-aws-kubernetes/variables.tf\nOur AWS Kubernetes module is now fully written.\ncode by running the following Terraform commands:\nmodule-aws-kubernetes$ terraform fmt\nmodule-aws-kubernetes$ terraform init\nmodule-aws-kubernetes$ terraform validate\nGitHub, so that we can use this module in the sandbox environment:\n$ git commit -m \"kubernetes module complete\"\nWith the EKS module ready to go, we can go back to our sandbox Terraform file and\nCreate a sandbox Kubernetes cluster\nbox environment is defined in its own code repository and has its own Terraform file\nbut this time we’ll add a call to the Terraform module.\nple, we’ll just use those default values in our sandbox environment.\npass some of the output variables from our network module into this Kubernetes\nmodule so that it installs the cluster on the network we’ve just created.\nthose inputs, you’ll need to define the aws_region value for your installation.\nshould be the same as the value you used for the network module and the backend\nUpdate the main.tf file of your sandbox environment so that it uses the Kubernetes\nmodule you’ve just created.\nmodule \"aws-eks\" {\nvpc_id             = module.aws-network.vpc_id\ncluster_subnet_ids = module.aws-network.subnet_ids\nnodegroup_subnet_ids     = module.aws-network.private_subnet_ids\ncreate a working EKS cluster.\nThe AWS EKS cluster we’ve defined here will accrue charges even\nYou can test that the cluster has been provisioned by running the following AWS CLI\n$  aws eks list-clusters\ntime to release our services into our environment’s Kubernetes cluster.\nWe’ll continue to follow the module\npattern by creating a Terraform module for Argo CD that we can call to bootstrap the\nUnlike the other modules, we’ll be installing\nTo do that, we’ll need to let Terraform know that we’re using a different host.\nnow, we’ve been using the AWS provider, which lets Terraform communicate with\nFor our Argo CD installation we’ll use a Kubernetes provider;\nWe’ll install this resource into the Kubernetes cluster rather than on the AWS\nInstead, we’ll use Terraform’s\nCreate a file called main.tf file in the root directory of the module-argo-cd Git reposi‐\nmodule-argo-cd/main.tf\nTo configure the Kubernetes provider, we’re using the properties of the EKS cluster\nAWS authenticator to connect to the cluster along with the certificate that we’ve\nmodule-argo-cd/main.tf (Helm)\nThis code creates a namespace for the Argo CD installation and uses the Helm pro‐\nCreate a file called variables.tf in your Argo CD module repository and add the code\nmodule-argo-cd/variables.tf\nvariable \"kubernetes_cluster_id\" {\nvariable \"kubernetes_cluster_name\" {\nWe need to define these variables so that we can configure the Kubernetes and Helm\nSo we’ll need to grab them from the Kubernetes module’s out‐\nmodules:\nmodule-argocd$ terraform fmt\nmodule-argocd$ terraform init\nmodule-argocd$ terraform validate\nthem to the GitHub repository so that we can use the module in our sandbox\nNow, as we’ve done before, we just need to call this module from our sandbox\nbootstrapping, so we need to call the module from the Terraform definition in our\nmodule’s main.tf file to install Argo CD.\nDon’t forget to use your module’s GitHub\nkubernetes_cluster_id        = module.aws-eks.eks_cluster_id\nkubernetes_cluster_name      = module.aws-eks.eks_cluster_name\nkubernetes_cluster_cert_data = module.aws-eks.eks_cluster_certificate_data\nkubernetes_cluster_endpoint  = module.aws-eks.eks_cluster_endpoint\neks_nodegroup_id = module.aws-eks.eks_cluster_nodegroup_id\nwon’t be a Kubernetes cluster for Argo CD to be deployed to.\nEarlier in this chapter, when we were creating the Terraform code for our Kubernetes\nmodule, we added a local file resource to create a kubeconfig file.\nTo use it, you just need to set an environment variable called KUBECONFIG that points\ncall to the Kubernetes cluster we’ve just created.\nLater in the process, we’ll get a chance to use Argo CD, the Kubernetes cluster, and\nInstall the Terraform providers that our environment code uses (we’ll need these\nWhen it’s done all of the AWS resources that we created will be gone.\nWe’re able to destroy these AWS resources from our local\nAWS CLI command to list EKS clusters:\n$ aws eks list-clusters\nIf something has gone wrong, you’ll need to use the AWS console and remove the\nWe created a Terraform module for our software-defined\nmodule that instantiates an AWS EKS cluster for Kubernetes.\nmented a sandbox environment as code that uses all of these modules in a declarative,\nthe Terraform module pattern and some of the design decisions you’ll need to make\nwe may need additional infrastructure modules, but later in the book we’ll use pre‐",
    "keywords": [
      "AWS",
      "Terraform",
      "Kubernetes",
      "’ll",
      "Kubernetes module",
      "Microservices Infrastructure",
      "Module",
      "AWS EKS",
      "Terraform module",
      "Infrastructure",
      "EKS",
      "Terraform code",
      "AWS EKS cluster",
      "AWS Kubernetes module",
      "Kubernetes cluster"
    ],
    "concepts": [
      "terraform",
      "modules",
      "module",
      "aws",
      "network",
      "networks",
      "networking",
      "resources",
      "resource",
      "kubernetes"
    ]
  },
  {
    "chapter_number": 8,
    "title": "Developer Workspace",
    "start_page": 195,
    "end_page": 195,
    "summary": "Developer Workspace\nIn Chapter 1 we discussed how a microservices architecture is typically most benefi‐\nearly in setting up repeatable, predictable, standardized development processes that\nyour developers.\nline for their microservice in their own way, without any consistency with the code‐\nCreating a new microservice should be a quick and",
    "keywords": [
      "Developer Workspace",
      "CHAPTER",
      "microservices",
      "predictable",
      "thing",
      "complex systems",
      "Workspace",
      "complex",
      "Developer",
      "developers",
      "pipelines",
      "intuitive",
      "architecture",
      "creating",
      "avoid"
    ],
    "concepts": [
      "developer",
      "developers",
      "developing",
      "microservices",
      "microservice",
      "development processes",
      "process",
      "predictable",
      "intuitive",
      "intuitively"
    ]
  },
  {
    "chapter_number": 9,
    "title": "to properly lay out",
    "start_page": 196,
    "end_page": 246,
    "summary": "ment workspace is set up and what practices teams use for creating code.\nsome of our past microservices projects.\nstart both vanilla Docker as well as a lightweight Kubernetes locally.\nstructure that’s ready for writing some microservices code.\nour code, when we get into the development phase of our implementation.\nCoding Standards and the Developer’s Setup\nthat a new developer unfamiliar to the code should be able to set up a microser‐\nNew microservices can be created quickly, easily, and predictably\ncode, we should only expect to see the Docker runtime and Docker Compose on\nCoding Standards and the Developer’s Setup \nSetup should work regardless of whether a developer runs code on their own lap‐\nA microservices\n4. Running a single microservice and/or a subsystem of several ones should be equally\nLet’s say an airlines reservation system is implemented as three microservices.\ndeveloper should be able to check out any particular microservice individually\nand work on it, or check out an entire subsystem of interacting microservices\n(the reservation system implementation) and work on that.\ncode into a Docker container, but making a containerized coding environment\na. Even though the code runtime is containerized, developers must be able to\nUse a Dockerfile for building a container image, and Docker Compose for\nCoding Standards and the Developer’s Setup \nfacilitate painless data management in a microservices environment:\nc. Running database migrations should be part of the project launch (via Make\nd. Running database migrations must be automated and should be part of any\nc. Check out this example of using Node’s db-migrate-sql for a MySQL\nplatform/stack in which code is being developed (e.g., JUnit for Java).\ndeveloper of the service should not need to set anything up to get things going\nand should be able to easily run tests with a command like make test-all.\na higher level (e.g., an API that invokes microservices, or a UI), or in some\ndeveloper clones, they should know that by running make run they can bring that\nyour microservice makefiles:\nCoding Standards and the Developer’s Setup \n• start: Run the code.\n• build: Build the code (typically a container image).\n• exec: Execute a custom command inside the code’s container.\nCheck out example microservices in Go and Node that follow the aforementioned\ndevelopment setups is code containerization with Docker.\nmake for running makefiles) should be the only expectation for a developer environ‐\na complete Docker toolset, or even single-node Kubernetes, if needed, on various\na problem that Docker4Mac only allows you to install one Docker instance and one\nallows you to very quickly launch Ubuntu-based Docker hosts on your macOS or\ndocker                  Running           192.168.64.3     Ubuntu 20.04 LTS\ndocker                  Running           192.168.64.3     Ubuntu 20.04 LTS\ndubuntu                 Running           192.168.64.4     Ubuntu 20.04 LTS\nYou can install Docker inside a container by following the usual Docker installation\nubuntu@dubuntu:~$ sudo apt-get install build-essential -y\nubuntu@dubuntu:~$ sudo apt-get remove docker \\\nubuntu@dubuntu:~$ sudo snap install docker\ngroup access to Docker, as shown in the following code.\nubuntu@dubuntu:~$ sudo groupadd docker\nubuntu@dubuntu:~$ sudo usermod -aG docker $USER\nubuntu@dubuntu:~$ docker ps\nubuntu@dubuntu:~$ docker version\nubuntu@dubuntu:~$ $ docker-compose --version\nTo test our new Docker setup, let’s now use it for bringing up a MySQL database with\nFirst, let’s create a mysql-stack.yml file with instructions for Docker Compose:\nDocker container with the following:\nubuntu@dubuntu:~$ docker-compose -f mysql-stack.yml up -d\nubuntu@dubuntu:~$ docker ps\nponents, such as a local Cassandra database, should you need to do so.\nAdvanced Local Docker Usage: Installing Cassandra\nWe have already discussed how to use Docker Compose for running a containerized\nMySQL database, but let’s look now at a somewhat more complex example of running\ncloud native microservices development journey.\nFirst, create a docker-compose.yml file with the following content anywhere in the\nubuntu@dubuntu:~/cassandra$ docker-compose up -d\nubuntu@dubuntu:~/cassandra$ docker-compose ps\nubuntu@dubuntu:~/cassandra$ docker exec -it cassandra-seed cqlsh\ncomponents and microservices that make up your overall application.\nTo install Kubernetes locally with k3s, use the following:\ncalled Skaffold was developed to make building container images pluggable into\nWe will not use local Kubernetes in most coding examples in this book, but if you\nwould like to take a look at a sample open source project implementing such a setup,\ncheck out the Skaffold microservices repository that we created for demonstration\nDeveloping Microservices\nThe implementation of the microservices in this sam‐\nWe will start by identifying fitting candidates for microservices based on a bounded\ndevelopment environment for the microservices is properly set up and configured,\numbrella project—a way to execute multiple microservices together in a developer\nDesigning Microservice Endpoints\n• Flights management\nour first two microservices can be ms-flights and ms-reservations!\nNow that we have the target microservices identified, we need to use the SEED(S)\n• The customer trying to book the flight\n• The flights management microservice: ms-flights\n• The reservations management microservice: ms-reservations\n1. When a customer interacts with the UI, the app needs to render a seating chart\n2. When a customer is finalizing a booking, the web app needs to reserve a seat for\nthe customer, so the app can avoid accidental seat reservation conflicts.\nusually jobs for which a BFF API needs microservices.\nmore technical JTBDs, describes the needs between the BFF APIs and microservices:\n1. When the API is asked to provide a seating chart, the API needs ms-flights to pro‐\nvide a seating setup of the flight, so the API can retrieve availabilities and render\n2. When the API needs to render a seating chart, the API needs ms-reservations to\nprovide a list of already reserved seats so the API can add that data to the seating\n3. When the API is asked to reserve a seat, the API needs ms-reservations to fulfill\nthe reservation, so the API can reserve the seat.\nNote that we don’t let ms-flights call ms-reservations to assemble the seating chart,\nChapter 9: Developing Microservices\nparticipant \"ms-flights\" as msf\ncust -[#blue]-> app ++: \"Flight Seats Page\"\napp -[#blue]-> api ++ : flight.getSeatingSituation()\nmsf --> api: flight_id\napp-[#blue]->api ++: \"book the seat\"\nto get a flight_id from the ms-flights microservice.\nWith the unique flight_id\nreturned, the API will then get the list of seats from ms-flights.\nshow occupied seats, it will separately query ms-reservations for existing reservations\non the flight.\nDesigning Microservice Endpoints \nThis is entirely why ms-flights is not querying the\nlist of reserved seats from ms-reservations directly.\nreserve it.\nTo fulfill this task, API will again need to auth and then call a microservice,\nms-reservations, returning the status, success, or failure to the app, based on the\nChapter 9: Developing Microservices\nWe will do this for both ms-flights and ms-reservations.\nFlights Microservice\nTo compile actions and queries for ms-flights:\nGet flight details\n• Input: flight_no, departure_local_date_time (ISO8601 format and in the local\n• Response: A unique flight_id identifying a specific flight on a specific date.\npractice, this endpoint will very likely return other flight-related fields, but those\nGet flight seating (the diagram of seats on a flight)\n• Input: flight_id\n• Response: Seat Map object in JSON format1\nReservations Microservice\nTo compile actions and queries for ms-reservations:\nQuery already reserved seats on a flight\n• Input: flight_id\nReserve a seat on a flight\n• Input: flight_id, customer_id, seat_num\n• Expected outcome: A seat is reserved and unavailable to others, or an error fired if\nDesigning Microservice Endpoints \nwe’ll see what this specification for our two microservices could look like.\ntitle: Flights Management Microservice API\nAPI Spec for Flight Management System\nshould also describe the response JSON’s structure, containing flight_id, the origin\n/flights:\nGET http://api.example.com/v1/flights?\nflight_no=AA2532&departure_date_time=2020-05-17T13:20\n- name: flight_no\ndescription: Flight Number.\nChapter 9: Developing Microservices\nflight_id:\nWhen you design the specification for the /flights/{flight_no}/seat_map end‐\n/flights/{flight_no}/seat_map:\nsummary: Get a seat map for a flight\nv1/flights/AA2532/datetime/2020-05-17T13:20/seats/12C\n- name: flight_no\nDesigning Microservice Endpoints \nChapter 9: Developing Microservices\nDesigning Microservice Endpoints \nOAS for ms-flights rendered with Swagger Editor\nSimilarly to the OAS of the flights microservice, the designs for the endpoints of the\ntitle: Seat Reservation System API\n/reservations:\nChapter 9: Developing Microservices\nsummary: Get Reservations for a flight\nGet all reservations for a specific flight\n- name: flight_id\nsummary: Reserve or cancel a seat\nReserves a seat or removes a seat reservation\nflight_id:\nDesigning Microservice Endpoints \ndescription: \"Seat already reserved.\nceed to the last step in the SEED(S) process: writing the code for the microservices.\nAs we implement the flights and reservations microservices, we will practice the prin‐\nThe reservations microservice will be implemented in Python and Flask,\nwhile the flights microservice will be implemented in Node/Express.js.\nImplementing the Data for a Microservice\nRedis for the reservations and MySQL for flights.\nwith the data for the reservations system microservice.\nChapter 9: Developing Microservices\nRedis for the Reservations Data Model\nIn the reservations system, we need to be able to capture a set of seat reservations for\na flight, and reserve a seat if it is not already booked.\nage for seat reservations information.\nflight_id (specific flight) where keys of the hash are the seat numbers on the flight\nand the value is the customer_id for the customer that the seat is already reserved for.\nwe need to know all reserved seats), and, very conveniently, a command that allows\nfect for us, since we typically do not want to allow double-booking a seat on a flight.\nKey Decision: Use Redis to Implement the Reservations Database\nUse Redis as the data store for reservations to leverage its unique simplicity and flexi‐\nbility, characteristics fitting for the implementation of this microservice.\nLet’s see an example of reserving several seats on a flight uniquely identified with the\nflight_id of 40d1-898d-bf84a266f1b9.\nuse the Redis CLI from the reservations microservice’s workspace by invoking make\n> HSETNX flight:40d1-898d-bf84a266f1b9 12C e0392920-a24a-b6e3-8b4ebcbe7d5c\n> HSETNX flight:40d1-898d-bf84a266f1b9 3B 0c27f7c8-a24b-9556-fb37c840de89\n> HSETNX flight:40d1-898d-bf84a266f1b9 22B 24ae6f02-a24b-a149-53d7a72f10c0\nImplementing the Data for a Microservice \nLet’s see how we would get all of the occupied seats on a specific flight:\nLet’s now see what happens if we try to double-book an already reserved seat, such as\nAs you can see, choosing Redis as the data store for ms-reservations has made the\nTo demonstrate this, in the next section, we will implement the data for the ms-flights\nmicroservice using a traditional SQL database.\nChapter 9: Developing Microservices\nMySQL Data Model for the Flights Microservice\nThe first data model we need here should contain seat maps.\nfor the flights microservice, the seat map is a complex JSON object.\nAdditionally, in the lookup endpoint we need to query data by two fields: flight_no\nAnother table we need is the mapping of flight_ids with flight_nos and date\nCREATE TABLE `flights`  (\nPRIMARY KEY (`flight_id`),\nREFERENCES seat_maps(flight_no)\nImplementing the Data for a Microservice \nINSERT INTO `seat_maps`(`flight_no`, `seat_map`, `origin_code`, /\n`destination_code`) VALUES ('AA2532', '{\\\"Cabin\\\": [{\\\"Row\\\": [{\\\"Seat\\\": /\nNow that we have a working data model for both of our microservices, we can dive\nImplementing Code for a Microservice\nNode.js-implemented flights microservice we’ll use a popular bootstrapper, Node‐\nFor the Python-based reservation microservice we’re going to use a Git‐\nHub template repository that contains most of the boilerplate code that we’ll need.\nKey Decision: Start Microservices with Reusable Templates\nUse code templates to jump-start a microservice development in each programming\nDocker installation and the GNU Make, since we use both of them.\nChapter 9: Developing Microservices\nEdit Code on a Host Run Inside Containers\nAs you work on a containerized project, your favorite code editor would be installed\nThe Code Behind the Flights Microservice\nTo use NodeBootstrap for jump-starting a Node/Express microservice, either install\nOnce you have created a new repository for the ms-flights microservice, at the desti‐\nnation of your choosing, let’s check it out on your developer machine and start modi‐\nImplementing Code for a Microservice \ndocker run -d --rm --name ms-nb-docs -p 3939:80 -v \\\nms-flights/docs/api.yml:/usr/share/nginx/html/swagger.yaml \\\nRendered OAS of the ms-flights microservice\nflights management one, let’s rename that folder flights and delete another default\napp.use('/flights', require('flights')); // Attach to sub-route\nChapter 9: Developing Microservices\nOnce you are done making these modifications, edit lib/flights/controllers/mappings.js\nthe microservice that will be invoked for each of your two API endpoint routes:\nconst flightNoValidation = check('flight_no',\n'flight_no must be at least 3 chars long and contain letters and numbers')\nrouter.get('/:flight_no/seat_map', seatmapsValidator, actions.getSeatMap);\nWe can create several database migrations with some make commands, as follows:\n→ make migration-create name=seat-maps\nms-flights-db is up-to-date\nStarting ms-flights ...\ndocker-compose -p msupandrunning exec ms-flights\nImplementing Code for a Microservice \n./node_modules/db-migrate/bin/db-migrate create seat-maps --sql-file\n[INFO] Created migration at /opt/app/migrations/20200602055112-seat-maps.js\n/opt/app/migrations/sqls/20200602055112-seat-maps-up.sql\n/opt/app/migrations/sqls/20200602055112-seat-maps-down.sql\n→ make migration-create name=flights\nms-flights-db is up-to-date\nms-flights is up-to-date\ndocker-compose -p msupandrunning exec ms-flights\n./node_modules/db-migrate/bin/db-migrate create flights --sql-file\n[INFO] Created migration at /opt/app/migrations/20200602055121-flights.js\nat /opt/app/migrations/sqls/20200602055121-flights-up.sql\nat /opt/app/migrations/sqls/20200602055121-flights-down.sql\n→ make migration-create name=sample-data\nms-flights-db is up-to-date\nms-flights is up-to-date\ndocker-compose -p msupandrunning exec ms-flights\n./node_modules/db-migrate/bin/db-migrate create sample-data --sql-file\n/migrations/sqls/[date]-seat-maps-up.sql\nChapter 9: Developing Microservices\n/migrations/sqls/[date]-flights-up.sql\nCREATE TABLE `flights`  (\nPRIMARY KEY (`flight_id`),\nREFERENCES seat_maps(`flight_no`)\nproject start to keep various installations consistent), or you can explicitly run a task\n1. Change ms-nodebootstrap-example to ms-flights in a variety of files, if you\n2. Modify the rest of the source code to implement the flights and seat_maps\nms-flights Full Source Code\nYou can see a working version of the sample ms-flights code on this\nWhen everything is working, you should be able to access your /flights endpoint\nImplementing Code for a Microservice \nhttp://0.0.0.0:5501/flights?flight_no=AA34&departure_date_time=2020-05-17T13:20\nhttp://0.0.0.0:5501/flights/AA2532/seat_map\ncheck out this book’s /ms-flights repository, which has every modification required.\ncontainer-management solutions (e.g., Kubernetes, which we will use later in this\nKey Decision: Starting Microservices from Reusable Templates\nto modify it for the ms-flights codebase.\nLet’s start by replacing lines 13–17 in appConfig.js with code like the following:\nChapter 9: Developing Microservices\nthe health-check middleware (the module we use) to only run an expensive, database-\nIf everything was done correctly and the microservice is up and running in a healthy\nImplementing Code for a Microservice \nmicroservice implementation on this book’s GitHub repository.\nNow that we have a fully functioning ms-flights microservice implemented with\nNode.js and MySQL, let’s switch to the code behind the ms-reservations microservice.\nIntroducing a Second Microservice to the Project\nWe are going to implement a second microservice (ms-reservations) in Python and\nstrap one we just used for ms-flights: it only requires working with Docker and make,\nhas all of the make targets to support a smooth development experience, just like\nUnlike MySQL, Redis doesn’t really use database schemas, so there’s no burning need\nJust like with ms-flights, we’ll start our code modifications by placing the proper OAS\nwe developed earlier in this chapter into the docs/api.yml of the new ms-reservations\nfile from the main one!), you should see the API specification for reservations ren‐\nChapter 9: Developing Microservices\nRendered OAS of the ms-reservations microservice\nWe will start modifying our template microservice by implementing the reservation\nwith the one for PUT /reservations, like this:\n\"\"\"Endpoint that reserves a seat for a customer\"\"\"\nTo fully implement this endpoint, we also need to create a handler for the mapping\nIntroducing a Second Microservice to the Project \nMost importantly, we need to implement the actual save to the database in src/\n\"\"\"Saves reservation into Redis database\"\"\"\nseat_num = reservation['seat_num']\nthis.tblprefix + reservation['flight_id'],\n\"error\" : f\"Unexpected error reserving {seat_num}\"\nlog.error(f\"Unexpected error reserving {seat_num}\", exc_info=True)\n\"error\" : f\"Could not complete reservation for {seat_num}\",\n\"description\" : \"Seat already reserved.\nRedis for the data model of the reservations microservice.\nThe microservice template we used readily contains all of the code required to grab\nChapter 9: Developing Microservices\nonce again the significant benefits of leveraging code templates for microservices\nable to run make from the top level of the source code, which will build and run the\ndocker-compose -p ms-workspace-demo logs -f ms-template-microservice\nAttaching to ms-template-microservice\nms-template-microservice    | [INFO] Starting gunicorn 20.0.4\nms-template-microservice    | [INFO] Listening at: http://0.0.0.0:5000 (1)\nms-template-microservice    | [INFO] Using worker: sync\nms-template-microservice    | [INFO] Booting worker with pid: 15\ncombined app and database logs by running make logs, or just the database logs by\nNow let’s run several curl commands to insert a couple of reservations:\n--data '{\"seat_num\":\"12B\",\"flight_id\":\"werty\", \"customer_id\": \"dfgh\"}' \\\nhttp://0.0.0.0:7701/reservations\n--data '{\"seat_num\":\"12C\",\"flight_id\":\"werty\", \"customer_id\": \"jkfl\"}' \\\nhttp://0.0.0.0:7701/reservations\nverify this by attempting to reserve an already reserved seat (e.g., 12C):\n--data '{\"seat_num\":\"12C\",\"flight_id\":\"werty\", \"customer_id\": \"another\"}' \\\nIntroducing a Second Microservice to the Project \n>   --data '{\"seat_num\":\"12C\",\"flight_id\":\"werty\", \"customer_id\": \"another\"}' \\\n> PUT /reservations HTTP/1.1\n\"description\": \"Seat already reserved.\nresp = handlers.get_reservations(flight_id)\ndef get_reservations(flight_id):\nreturn model.get_reservations(flight_id)\nThe model code will look like the following:\ndef get_reservations (flight_id):\n\"\"\"List of reservations for a flight, from Redis database\"\"\"\nkey = this.tblprefix + flight_id\nChapter 9: Developing Microservices\n→ curl -v  http://0.0.0.0:7701/reservations?flight_id=werty\n> GET /reservations?flight_id=werty HTTP/1.1\nms-reservations Full Source Code\nYou can see a working version of the sample ms-reservations code\nPlease take a look and try to use various make targets available in the repository to\nNow what we need to do is figure out a way to execute these two microservices (and\nIntroducing a Second Microservice to the Project \nDeveloping individual microservices is how teams should be spending most of their\nsome point we do need to try the entire project—all microservices working together.\nWe need an easy-to-use umbrella project, one that can launch all of our microservice-\nTo deploy an easy-to-use umbrella project, we’ll use the microservices workspace\ndescend into a subfolder of your workspace repository containing a microservice and\nnew workspace, by editing the fgs.json file to look something like the following:\n\"ms-flights\" : {\n\"url\"  : \"https://github.com/implementing-microservices/ms-flights\"\n\"ms-reservations\" : {\n\"url\" : \"https://github.com/implementing-microservices/ms-reservations\"\nChapter 9: Developing Microservices\nIn the last configuration we indicated ms-flights and ms-reservations using the read-\nNow that we have configured repos.json, let’s pull the ms-flights and ms-reservations\nmicroservices into the workspace:\nhttps://github.com/implementing-microservices/ms-flights ms-flights\nCloning into 'ms-flights'...\nhttps://github.com/implementing-microservices/ms-reservations ms-reservations\nCloning into 'ms-reservations'...\nWe also need to edit the bin/start.sh and bin/stop.sh scripts to make changes from the\npushd ms-flights && make start\npushd ms-reservations && make start\npushd ms-flights && make stop\npushd ms-reservations && make stop\ncompose.yml files of both microservices to ensure proper routing of those services, as\nms-flights/docker-compose.yaml\nms-flights:\ncontainer_name: ms-flights\n- \"traefik.http.routers.ms-flights.rule=PathPrefix(`/reservations`)\"\nms-reservations/docker-compose.yaml\nms-reservations:\ncontainer_name: ms-reservations\n- \"traefik.http.routers.ms-reservations.rule=PathPrefix(`/reservations`)\"\nOnce you bring up the workspace by running make start at the workspace level, you\nfore, the following two commands are querying the reservations and flights systems:\n> curl http://0.0.0.0:9080/reservations?flight_id=qwerty\nhttp://0.0.0.0:9080/flights?\\\nflight_no=AA34&departure_date_time=2020-05-17T13:20\nChapter 9: Developing Microservices\nIn this chapter we brought together a lot of system design and code implementation\nthe design of individual data models, and learned how to quickly jump-start code\nmake a material difference in your ability to execute microservice projects success‐",
    "keywords": [
      "flight",
      "microservices",
      "Developing Microservices",
      "seat",
      "Docker",
      "Flights Microservice",
      "code",
      "Ubuntu",
      "ubuntu ubuntu",
      "chapter",
      "Docker Compose",
      "API",
      "Flights",
      "flights management microservice",
      "developer workspace"
    ],
    "concepts": [
      "flight",
      "flights",
      "flight_no",
      "microservices",
      "microservice",
      "reservation",
      "reservations",
      "reserve",
      "reserved",
      "reserves"
    ]
  },
  {
    "chapter_number": 10,
    "title": "Releasing Microservices",
    "start_page": 247,
    "end_page": 278,
    "summary": "Next, we’ll augment our code repository with a container\nWith a container ready to go, we’ll implement a deployment process\nStaging deployment\nBecause of the scope of what we need to cover, we’ll only deploy the\nTo make all this work, we’ll be using three different GitHub repositories with their\nThree code repositories for deployment\nUp until now, we’ve been deploying microservices into a local developer environ‐\nNow we’ll take the same services we’ve built and tested locally and deploy them\nIn this section, we’ll build the staging infra‐\nwe’ll need to update that infrastructure code to reflect the needs of the flight informa‐\n• An AWS-based MySQL database instance for the flights microservice’s data\nBut since we’ve already covered that in detail, this time we’ll use code and\nalso a fine choice: since we’ve already started using it in the development stage, we’ll\nWe’ll use Traefik to route messages from the load balancer to microservices deployed\nWe’ll be able to use this module in our Terra‐\nWe’ll get a chance to use this ingress module in “Forking the Staging Infrastructure\nwe’ll support our database needs.\nEach of our microservices use different databases, so we’ll need to provision two dif‐\nWe’ll need both a MySQL and a\nThe platform team will create Terraform-based modules to provision AWS hosted\nIn our database module, we’ll use the AWS ElastiCache service to provision a Redis\nwork configuration and access policies that the database service needs for operation.\nWhen the module is applied to the staging environment, we’ll have both a Redis and a\nmodules in a Terraform code file and provision an environment.\nThe staging environment we need for releasing our microservices will be very similar\nWe’ll use Terraform to define the environ‐\nment in code and we’ll use the modules we wrote for the network, Kubernetes cluster,\nFinally, we’ll use a GitHub Actions pipeline\nInstead, we’ll use a staging environment skeleton project\nWe’ll need to make a few small\nchanges to the code so that it will work in your AWS environment.\nStarting with the staging environment repository\nTo fork the staging environment repository, follow these steps:\nwe’ll need to update is the GitHub Actions workflow.\nThe forked CI/CD workflow we’ve just created won’t be able to access your AWS\nSo we’ll need to add AWS access management creden‐\nvalue microservices for the MYSQL_PASSWORD secret.\nWhen we forked the infra-staging-env repository, GitHub made a copy of the Actions\nwe just need to make a few adjustments to the Terraform code that creates the staging\nnetes cluster that we’ll create on EKS.\nThe Terraform code that we’ve written for you will provision a staging environment.\nTo do that, we’ll work on the files in your\nAlso, you’ll need to create a clone of your forked infra-staging-env\nWe’ll be editing the main.tf file that defines the staging environment.\nTo solve that problem, we’ll need to give our AWS operator a few more permissions.\nWe’ll do this by creating a new IAM group for database work.\nRun the following AWS CLI command to create a new group called DB-Ops:\nFinally, use a CLI command to add our Ops account to the group we’ve just created:\nLet’s start by committing our updated Terraform code to your forked repository:\nUse the following Git commands to create a new v1.0 tag and\njob has succeeded, you now have a staging environment with a Kubernetes cluster\nWe’ll need that Kuber‐\nnetes cluster for our microservices deployment.\nIn order to communicate with the staging Kubernetes cluster we’ll need the configu‐\nconfiguration file and update our local environment settings.\nSet up your Kubernetes client environment by downloading the kubeconfig file that\nfirm that our staging cluster is running and the Kubernetes objects have been\ndeployed.\nIn the result you should see a list of all the Kubernetes services that we’ve deployed.\nThat means that our cluster is up and running and the services we need have\nThe last step we need to take care of is setting up a Kubernetes secret.\ninformation microservices connects to MySQL, it will need a password.\nRun the following command to create and populate the Kubernetes secret for the\nWe now have a staging environment with an infrastructure that fits the needs of the\nas containers so that we can deploy them into the environment.\nIn Chapter 9, we used make to test, build, and run microservices locally in a develop‐\nBut in order to build and deploy our services into testing, staging,\nLet’s start by taking a look at Docker Hub, the container registry we’ll be using to host\nstaging environment, we’ll need a way to move them, or ship them over.\nthis book, we’ll use Docker’s publicly hosted registry called Docker Hub. We’ve\nKey Decision: Use Docker Hub as a Container Registry\nWe’ll be shipping our microservice container into a Docker Hub container registry.\nYou can create a repository for our flight application\nIn order to use Docker Hub, you’ll need to have a Docker account.\nWith a Docker account and a container repository, we’re ready to build and push con‐\nsistency we’ll use Actions again as the pipeline for our microservices container builds.\nWe’ll create our GitHub\nIf you don’t have your own flights service repository yet, you can create\nBuild a container in the flight service repository\nJust as we’ve done before, we’ll start our pipeline configuration by adding credentials\nSo we’ll need to add our Docker Hub access information as secrets in the\nflights GitHub repository.\nSpecifically, we’ll need to create and populate two secret\nThat’s because we won’t be deploying into an AWS instance in this pipeline.\nthe deployment of the containers into our staging environment.\nThis is a useful separation to create because we want our microservice containers to\nAll we need to do now is create the workflow that does the work of building, testing,\nShipping the flight service container\nIf you’ve forked the ms-flights repository, you’ll find that we’ve already written a Git‐\nWe’ve already added Docker Hub credentials to the repository, so the workflow is\nAll we’ll need to do is push a tag called v1.0 into the release to trigger\nWhen it’s done, the flights service container will be pushed and ready\nWe now have a containerized ms-flights microservice ready to be deployed into our\ncan move on to the work of deploying the container into our staging environment.\nDeploying the Flights Service Container\nWe now have all the pieces in place to deploy the flights microservice.\nsioned a test environment using our infrastructure pipeline and we’ve created a\ndeployable containerized image for the service.\nwe’ll use the Argo CD GitOps deployment tool we installed in our infrastructure\nof the flight information microservice deployed and ready for use.\nTo make repeatable deployment easier, we’ll be creating a new deployment repository\nbuild will describe how a microservice should be deployed.\npushed into the deployment repository, Argo CD will use them to deploy containers\nThe Helm package will define the service deployment\nAll of this deployment work will happen within the world of Kubernetes, so let’s get a\nUnderstanding Kubernetes Deployments\nthe work that needs to be done to start containers, check on their health, find serv‐\nmicroservices deployment, you will need to describe the optimal state for a running\nIn Kubernetes, we’ll define a set of special deployment\nbe deployed.\nstanding of five key objects in order to create a simple deployment package for our \nflights microservice: Pods, ReplicaSets, Deployments, Services, and Ingress.\nDocker containers that need to be started and managed together.\nDeploying the Flights Service Container \nDeployment\nThis is the main object you need to work with to create a Kubernetes\nDeployment.\nA Service defines how applications in the Kubernetes cluster can access this Pod\nmicroservice deployment.\nIn order to deploy our microservice, we’ll need to write declarative configurations for\nthe Ingress, Service, and Deployment objects.\nA Kubernetes Deployment can require a lot of communication with the cluster.\nneed to make multiple calls to the Kubernetes API, letting it know how, when, and\nwhere you want to deploy your containers.\nwe’ll use the Helm packaging tool.\ninstallation and deployment of application into a Kubernetes cluster.\nTo use Helm, we’ll first need to understand the three important concepts of charts,\nA chart is a bundle of files that describe a Kubernetes resource or deployment.\nlier in the book when we deployed Kubernetes-based applications like Argo CD.\ncalled templates because they contain special instructions that Helm uses to\nmicroservice and make the port number of the Service a templated value.\nTo create a flights Helm package, we’ll need to create a Helm chart.\nwe’ll define a set of template files that declare how the flights service should be\ndeployed.\nFinally we’ll create a values file for the staging\nour Helm charts to be available for Argo CD to retrieve and use.\nwe’ll need to do is create a microservices deployment repository to store and manage\nCreating the Microservices Deployment Repository\nWe’ll be keeping our Helm charts in a single “monorepo” of microservice deploy‐\nown their own Helm deployment charts and deploy into the deployment repository\nCreate a deployment package in the deployment repository\nTo get started, create a new GitHub repository called ms-deploy.\nDeploying the Flights Service Container \nThe deployment repository you’re creating now will become the\nThe easiest way to start working with Helm files is to use the Helm CLI application.\nIn our examples, we’ll be using Helm version 3.2.4, which you can find at\nWhen you’ve done that, you’ll be ready to create the ms-flights Helm chart.\nthe root directory of your ms-deploy repository and run the following command:\nms-deploy $ helm create ms-flights\nWhen it’s done, Helm will have created a basic package that contains a chart.yaml file\nto write for a basic microservices Kubernetes deployment has been handled for us\nWe’ll only need to make a few small changes to the templates that Helm has\nIn particular, we’ll need to update the templates/deployment.yaml file just a little bit to\nmake it more specific to the container that we want to deploy.\nUpdate the flights deployment template\nThe /ms-flights/templates/deployment.yaml file is a Kubernetes object description file\nwe’ll need to make a few small changes for this deployment to work for our flights\nDeployment.\nenvironment values that Kubernetes should use when it creates a replica of a Pod. For our simple deployment, we’re going to use the default values that Helm has gener‐\nBut we’ll need to update\nspec.template.containers so that it works for the ms-flights container that we’ve\nDeploying the Flights Service Container \nA completed example of the ms-flights Helm chart is available at\n• The TCP port that the flights microservice will bind to and our container exposes\nThat’s all we need to customize to make the generated Helm templates work for us.\nWith the deployment template we’ve created, we have a parameterized Kubernetes\nWe’ll only need to define some values to use in the\nOne of the nice things about using a Helm package for deployment is that we can\nAnother option is to create a file that serializes all of the values you want to use in a\nThis is the approach we’ll take for our deployment package.\nthe advantage of being able to manage our deployment value files as code.\nWe’ll use\nFirst, we’ll need to update the details for the Docker image.\nThis example uses the container we’ve already built for you.\nwant to use your own, you’ll need to change the values of reposi\nNext, we’ll add MySQL connection values so the microservice can connect to the\nstaging environment’s database services.\nDeploying the Flights Service Container \nwon’t need to actually host the service at the flightsvc.com domain, we’ll just need to\nThe last thing we’ll need to do is a quick dry-run test to ensure that we haven’t made\nYou’ll need to have connectivity to your Kubernetes cluster, so\nIf everything looks good, commit the finished Helm files to the GitHub repository:\nNow that the package files are available in the deployment monorepo, we’re ready to\nuse them with the Argo CD GitOps deployment tool.\nSo far, we’ve created a Helm chart that gives us a more consumable way of deploying\nmicroservices into the Kubernetes cluster.\nforming deployments into Kubernetes clusters, so we’ve already done enough to be\nable to deploy the flight information service into the staging environment.\nuse the Helm CLI for every deployment.\nis necessary when our deployment repository is updated.\nway we deploy services into our environments.\nArgo CD is a GitOps deployment tool, designed to use a Git repository as the source\nArgo CD instance that we’ve installed in staging, point to our ms-deploy repository,\nBefore we can log in to Argo CD, we’ll need to get the password for the Argo admin‐\nCopy the name of the Pod somewhere as that will be the password we’ll use to log in.\nIn order to access the login screen and use our credentials, we’ll\nDeploying the Flights Service Container \ning a reference to our flight information service deployment.\nSync and deploy a microservice\nIn Argo CD, a microservice or workload that needs to be deployed is called an appli‐\nTo deploy the flight-information microservice we’ll need to create a new\nthe deployments monorepo and the ms-flights directory within it.\nUse the values in Table 10-4 to set up your flight-information microservice deploy‐\nMake sure you replace the value YOUR_DEPLOYMENTS_REPOSITORY_URL with the\nURL of the deployment repository from “Creating the Microservices Deployment\nFlight-information service values\nYOUR_DEPLOYMENTS_REPOSITORY_URL\nIf you’ve created the application successfully, Argo CD will list the flight-info applica‐\nDeploying the Flights Service Container \nDeployment declaration, and the flight-info application in our cluster doesn’t match\nDeployment yet.\nTo make that happen, click the flight-info application that we’ve just\nWhen you click Synchronize, Argo CD will do the work it needs to do to make your\nsmoothly, you’ll have a healthy, synchronized, and deployed microservice, as shown\nDeployed flight service\nOur container has been deployed in the Kubernetes cluster, its health checks and liv‐\nOur flights microservice is now up and running in our AWS-hosted staging environ‐\nIn order to test the service with a request message, we’ll need to access Traefik’s\nthing we’ll need is the load balancer’s network address.\nWe’ll be using curl to send a request message to the flights microservice.\nDeploying the Flights Service Container \nRun the following curl command to send a test request message to the flights service\nmessage to the flights microservice based on the ingress rule we defined earlier in this\nThe flights microservice retrieves data from the database service we provi‐\nAs we’ve done before, we’ll use a local Terraform client to bring down the infrastruc‐\nMake sure you’re in the directory where your staging Terraform files are and run\nWhen it’s successfully completed, our Kubernetes-based staging environment will be\nour microservice code repositories, and we built a new deployment repository and\ntool-based process to get services deployed.",
    "keywords": [
      "Flights Service Container",
      "Docker Hub",
      "’ll",
      "Kubernetes",
      "staging environment",
      "Helm",
      "Flights Service",
      "Releasing Microservices",
      "AWS",
      "deployment",
      "Microservices",
      "Docker",
      "Service Container",
      "CHAPTER",
      "environment"
    ],
    "concepts": [
      "deployment",
      "deploy",
      "deploying",
      "deployed",
      "deployments",
      "deployable",
      "microservices",
      "microservice",
      "container",
      "contains"
    ]
  },
  {
    "chapter_number": 11,
    "title": "Managing Change",
    "start_page": 279,
    "end_page": 296,
    "summary": "Managing Change\nWe have now built a microservices system that is optimized to reduce change costs.\nthe perspective of change.\nWe’ll explore what change looks like for the system we’ve\nWe’ll take a look at the typical kinds of change you’ll need to do and the pat‐\nChange is an important factor because of the impact it has.\nthe benefits of a microservices system is that it makes change faster and safer.\nAlso, change will always have a cost.\ntem, we need to minimize change cost and make changes that have the greatest\nReducing the cost of change gives all of our teams more freedom to experi‐\nmicroservices system and the best way to make decisions about change.\nChanges in a Microservices System\nIn a microservices system, change should be a feature, not a problem or a bug.\nmeans you should be able to change the system to make it better and get more value\nexample, here are some common reasons to make changes in your system:\nkinds of changes to make them as cost-effective as possible.\nProduct teams use data to make better informed decisions about the changes they\nhelp shape their strategic decision making and their backlog of changes.\n• Change time per microservice\n• Frequency of changes per microservice\n• Number of microservices changed per change request\ncan make against the impact that a change will have.\nThe Impact of Changes\nWhen we review change costs\nA core part of any change cost is the time it takes to actually make the change.\ncomponents to be changed.\nChanges in a Microservices System \nhave changed.\nthe downtime required for changes.\nAn often forgotten impact is the cost that a change has on the users of the system.\nexample, a change to an infrastructure module may have wide-reaching impact\nSoftware architecture has a big role to play in the costs and impacts of change across\nchanges are applied.\ning three deployment patterns that we’ll use when we make changes in our system:\nnext change.\nThis is a useful deployment pattern because it allows you to make changes in a pro‐\nPersistent, changing data needs to be\nfocus on a smaller, bounded change and make that change within a running system.\nChanges in a Microservices System \nThe multiple versions pattern makes changes more transparent to the users and cli‐\nrequire a dependent system to make a change as well.\nknow people we don’t coordinate with will need to do work for the change to be com‐\ncal deployment patterns we can use to describe how change might be handled.\nwe can dive into an evaluation of the architecture we’ve built from a change perspec‐\nchange through the factors of implementation costs, coordination time, downtime,\nInfrastructure Changes\nchange as the needs of users and teams evolve, and demand patterns and business\ngoals change.\nsystem, while changes to existing resources need to be managed more carefully.\n• Changing the network design of the VPC our EKS service is deployed within\nWe’ll need to consider both types of changes when we assess the changeability of our\nInfrastructure change: Implementation costs\nThe implementation cost of making infrastructure changes is a function of how diffi‐\nreduce the cost of making changes.\nWhen it comes time for you to make an infrastructure change, you can employ a\nchange process that looks something like this, thanks to the tools we’ve implemented:\n1. Decide on the infrastructure change you want to make.\n2. Identify the infrastructure code you need to change (e.g., do you need to create a\n3. Test the infrastructure change in an infrastructure development environment.\nWe only ever make changes through the infrastructure pipe‐\nchanges makes it a worthwhile investment.\nInfrastructure change: Coordination costs\ntem whenever an infrastructure change is needed.\nchanges.\nchanges?\nHow are new changes tested across all the teams?\nInfrastructure change: Downtime\nIt’s difficult to make infrastructure changes without introducing a little bit of down‐\nmake even a small change to a component, we need to first destroy it.\nTo make these kinds of in situ infrastructure changes, we could adopt the blue-green\nThis means we could spin up a new environment with our changes.\nchange process.\nInfrastructure change: Consumer impact\noperating model, we need to consider the impact of changes on our microservices\nWhen you change any part of the infrastructure, you’ll need to consider how that\nchange might impact all of the microservices teams consuming and using the plat‐\nture changes won’t break existing microservices.\ninvolved whenever changes are made.\nIn order to keep coordination costs light, the platform and microservices teams need\nchanges for the microservices teams to handle.\nMicroservices Changes\nMost of the changes you’ll need to make in the system will be to the microservices\nence works, or just fine-tune the system, chances are you’ll be making changes to the\nkind of change we can make.\nThings get more complicated when we need to change a\nthese kinds of changes:\nLet’s take a look at microservices changes through the lens\nof our four key change impacts.\nWhen it comes to changing a microservice, the main implementation costs come\nthat code comprehension should be improved and changes can be implemented\nchanges across the organizations.\nmaintainable state by the time it comes to make a new change.\nshould greatly reduce the costs of making code changes to microservices in our\nCoordination costs can be a big problem for making software changes.\nhaving to work with many other people and teams to understand if a change can be\nmicroservices code changes.\nnation costs for microservices code changes has been a primary driver for the archi‐\nThe kinds of changes that come from the system\ncation than code changes to an individual microservice.\nIt makes sense to optimize the change\nIt’s one thing to change the code of a microservice, but you’ll often find yourself\nneeding to change the interface of a microservice as well.\nchanges and the coordination costs that often come with them.\nultimately if the release team becomes a bottleneck to change, the system design must\nOverall, the coordination costs of microservices change within our architecture are\nAnother change area that we’ve optimized for is in minimizing the downtime\nrequired when an individual microservice is changed.\nmicroservice you can use the tooling we’ve installed to perform the following change\nThis pattern will work for most of the changes you need to make and you’ll be able to\ntern when a new version of the microservice will make a change that could impact the\nFor example, if a new version changes data in a shared database, make\nSo far, we’ve mostly focused on changes to microservices code.\nour changes will be found.\nBut sometimes you’ll need to make changes to the inter‐\nChanging the interface of a microservice is almost inevitable.\nof making changes.\nThe best way to reduce the consumer impact of an API change is\ning from the API change patterns in his book Design and Build\nwhen changing interfaces.\ncontract tests independently and validate that their changes will not impact existing\ntain an old microservice until the client team can make the changes they need to.\nimpact changes.\nplanning to make those changes affordable.\nData Changes\nData models are notoriously difficult to change.\nis a much needed part of any software system, but when it comes time to change the\ndependent on the data systems that they use and changing them can have a big cost\nmodel changes.\nlenses of change.\nAt its most basic level, the cost of changing a data model is a function of how complex\nto make the change.\ncost really comes from having to understand the model itself, so that changes can be\nmodel, in the same way it should help us reduce the cost of a code change.\nSo, just as with code changes, you should get a great deal of implementation cost ben‐\nBy deciding that microservices own their own data, we’re free to make changes\nusing a shared data service and changes need to be coordinated carefully across all\nWe’ve optimized our architecture for high-speed, autonomous local changes.\nmade system-wide changes more costly.\nFor example, if you need to globally change\nBut you’ll need to change that decision if the sys‐\nIf you find that you’re often making changes to multiple data mod‐\nBut it isn’t built for zero-downtime data model changes.\nWhen it comes time to make a change to a data\nservice uses, but we’ll still need to be wary of making changes that will break existing\nIn cases where we need to make an intrusive data model change, the simplest option\ninstances that can implement the data change.\nimpact of a data model change is restricted to the service itself.\nchanges without impacting the consumer of a service directly.\nautonomy to make changes to their model, although as we highlighted above, these\nIn practice, a data model change is likely to require code and even interface changes.\ncan be made first, before we implement changes that will impact consumers directly.\nOverall, we’ve seen that the architecture we’ve built is designed to make changes eas‐\nperspective of change.\nchange.",
    "keywords": [
      "Change",
      "changes",
      "microservices",
      "system",
      "make changes",
      "microservices system",
      "Infrastructure change",
      "Managing Change",
      "infrastructure",
      "make",
      "data",
      "architecture",
      "data model change",
      "’ll",
      "’ve"
    ],
    "concepts": [
      "change",
      "changed",
      "changing",
      "make changes",
      "microservices",
      "microservice",
      "data",
      "infrastructure",
      "infrastructures",
      "new"
    ]
  },
  {
    "chapter_number": 12,
    "title": "A Journey’s End (and a New Beginning)",
    "start_page": 297,
    "end_page": 319,
    "summary": "journey in successfully implementing microservices on real projects.\nexcuses for the fact that we are admirers of the microservices architecture and of the\nWe have witnessed many successful microservices projects.\nof failed attempts to adopting microservices.\ntheir system in the microservices style.\npragmatic guidelines on when, why, and how to deploy microservices, explaining\nunderstanding of the architectural decisions in microservices and an approach we\nOn Complexity and Simplification Using Microservices\nThroughout this book we have asserted that microservices are most applicable when\nutilized to implement large, complex, continuously changing systems.\nstatement makes sense: a microservices architecture itself is not simple, so embarking\ncomplex.\nBut what is the nature of complexity and how exactly do microservices\ndecrease complexity, if at all?\nA seminal work on software complexity is Fred Brooks’s 1986 article, “No Silver Bul‐\npresence of essential complexity in software systems.\ntion choices), the majority of the complexity that we deal with in software systems is\nnot accidental, it’s related to the very essence of the complexity of modeling the prob‐\ntem beyond its essential complexity, we would be taking away from its core model,\nWhen dealing with microservices, early adopters are often attracted by the promise of\nmicroservices making building complex systems…wait for it…simpler!\nwould rather microservices make it easier for them to get their jobs done than make\nmenting a “larger” system as a collection of many simple microservices, we are mak‐\nmicroservice may be small and simple, orchestrating a large number of them into a\none additional, troublesome question is: have microservices broken Brooks’s conjec‐\nOr is a microservices\narchitecture purely addressing the accidental part of system complexity, and does\nThe microservices concept is not just about acci‐\nof it (the code) and the operational part of it (the deployment and orchestration).\ncan make the code simpler by breaking it up into many small microservices.\nbut in reality this type of complexity shift can be quite beneficial if you can automate\nThe increased complexity of operations matters much less if they can be automated.\nof cloud services provided to us without us having to even think about it have made\nbuilding complex operations materially simpler, beyond anything Brooks could have\nTherefore, if we shift complexity from coding into\nMicroservices Can Provide Simplification\nA microservices architecture can be materially simpler than its\nalternatives when implementing complex systems.\nviolate Brooks’s “No Silver Bullet” principle because microservices\nRather, this architectural\nautomate, design and code, into the area we have gotten very good\nMicroservices Quadrant\nnition of a complicated system and a complex system.\nOn Complexity and Simplification Using Microservices \nwere to classify monoliths and microservices in these terms, monoliths would be con‐\nsidered complicated, whereas microservices would be much more aligned with the\ndefinition of complex systems.\nbe any more different, in the context of design.\nThe microservices quadrant (source: https://oreil.ly/IO5t8)\n• Microservices would be a complex implementation, but a simple design\n(architecture).\nsarily simple) architectural design.\ndesign (think minimal effort), and ended up with a complex implementation that\nThe microservices quadrant gives a shorthand representation of where microservices\nHaving discussed the nature of microservices architectures through the lens of com‐\nabout a microservice transformation over time.\nIn Chapter 11, we discussed both the role microservices architecture plays in helping\nteams tackle change in complex systems and techniques to manage change when\nimplementing microservices.\nto microservices: the transformation that an organization as a whole needs to go\ncessful with a microservices transformation by taking a holistic look at one and\nMeasuring the Progress of a Microservices Transformation\nWhen we discuss the migration to microservices, it’s important to remember that we\nIf you have followed the various critical posts published about microservices in the\nadopted a microservices architecture and wrote a cheerful blog post about its benefits\nservices’ complexity and praising a switch back to a monolith.\nWhile for some teams,\nprojects, or companies, microservices may indeed be the wrong choice, the reality is\nMeasuring the Progress of a Microservices Transformation \nThere is no turnkey software that teams can just buy from a vendor, or install with an\nreality, many traits of microservices architectures are aspirational and not directly\nquantifiable: independent deployability, decentralized governance, infrastructure\nautomation, and evolutionary architecture, among others, are not things that any\nteam can excel at right out of the gate or easily measure their progress toward!\nearly stages of microservices adoption is to establish a “microservi‐\nMigrating to microservices is a long\nThe thinking that teams need to adopt when considering their level of maturity vis-à-\nvis microservices traits is largely similar to the philosophy we described in Chapter 4\nwhen discussing rightsizing microservices: the size and granularity of a microservice\non a “perfect” microservices implementation as it relates to traits like independent\ndeployability and automation too early in the transformation process.\n• How automated does our infrastructure need to be in the early days?\n• What systems can we delegate to a cloud provider to manage (e.g., databases,\nsame time you’re also trying to adopt microservices, especially if your teams are unfa‐\nInstead, teams must concentrate on things that\nIt is extremely important to remember that microservices architec‐\nmicroservices architecture.\nIt is so fundamental that teams that can demonstrate\nSome teams try measuring “speed” or “safety,” but that is\nsame exact system once as a monolith and then as a microservices architecture.\ntrajectory of increasing team autonomy, and the third that best indicates the overall\n• The average size of an autonomous team, across all teams\n• The average length of time an autonomous team can work without getting halted\nMeasuring the Progress of a Microservices Transformation \nIn a healthy microservices transformation that is on the right trajectory, you should\nsee a gradual decrease in the size of autonomous teams and an increase in the amount\nof time that teams can work independently.\nage autonomous team size in your organization used to be 15 to 20 members and\nafter implementing microservices it starts to gradually decrease to 10, 8, 6…\nA coordination deadlock is a stoppage during which an autonomous team is\nwaiting on another team for a shared capability to be made available for them; e.g., an\ninfrastructure team provisioning a highly available Kafka or Cassandra cluster, or a\nsecurity review team completing a code audit.\nAnother common example of a team\nTracking the number of dependencies that a team needs to clear before a code release\ntype of event to track is whether teams need to often wait for other teams to make\ncode changes, caused by the change in a shared data model.\nThe third metric, deployment frequency, does not directly measure coordination\nbe a powerful indicator of team agility.\nmicroservices, in our experience it can also indicate the health of a microservices\nthe right track, teams can free themselves from the anxiety of achieving perfection in\nevery single microservices trait, freeing themselves for long-term success.\nMicroservices can make your complex systems simpler, but it is no “silver\nlook during a microservices transformation.\nsprint, and teams intending to be successful need to be equipped with proper tools\nWe wish you much success on your own microservices transformation journey and\nmicroservices in your own work.\nACID\nconsumer teams, 32-33\nmicroservices and, 3\nversus microservices, 54-56\narchitecture, 3\n(see also microservices)\ndata isolation, 85\nKubernetes module, 171-173\nEKS (Elastic Kubernetes Service), 113, 140\nDDD (domain-driven design), 59-62\narchitecture and, 266\ndata, 264-265\ndeployment patterns, 266\nmicroservices, 273\nmicroservices change, 274\ncloud platform teams, 29\ncollaboration interaction mode, Team Topol‐\ncollaboration, DDD (domain-driven design),\ncomplicated-subsystem teams, 22\ndata changes, 279\nmicroservice change, 276-277\nconsumer teams, 32-33\nAPIs, 32-33\nflights microservice, 246\nflights microservice, 244-246\ndata changes, 278\nmicroservice change, 274-275\ncross-functional teams, 18\ndata\ndata design, 9\ndata duplication, independence and, 81-82\ndata implementation, 208\nMySQL data model, 211-212\ndata management, 75\nACID transactions, 83\ndata space co-ownership, 76\ndata modeling, Event Sourcing and, 89\ndata sharing, 77\ndatabase module, staging environment, 234\nACID and, 82\nembedded data and, 78\nmake commands, 215\nshared data, 81\ndeployment, 76\n(see also independent deployability)\ncontainers, flights microservice, 246\nKubernetes, 247\nDeployment controller, Kubernetes, 248\ndeployment template, 250\ndesign\ndata design, 9\nmicroservice design, 9\nteam design, 8\nTeam Topologies, 24\ndata changes, 278\nmicroservice change, 275\nEKS (Elastic Kubernetes Service), 113, 140\nembedding data, 77\nenabling teams, 22\nendpoint design, 197\nenvironment variables, MySQL databases, 252\ndata management and, 89\ndata modeling and, 89\nmicroservices change, 273\nfacilitating interaction mode, Team Topology,\nflights microservice\ndeployment template, 250\ndeployment, 255\nHelm (Kubernetes), 171, 248-249\nTerraform files, 130-131\ndata changes, 277\nmicroservice change, 273-274\nindependent deployability, 76\ndata duplication and, 81-82\nindexes, shared data, 81\nKubernetes, 139\nKubernetes module, 160\ningress module, staging environment, 233-234\nendpoint design, 198-201\nKubernetes, 139\ndeployment, 247\nDeployment controller, 248\nEKS (Elastic Kubernetes Service), 148\nlocal variables, Terraform modules, 147\ndesign), 62-65\nmicroservice architecture, 3\n(see also microservices)\nmicroservice design, 9\nmicroservice-bootstrap, 274\nmicroservices\ncomplex, 282-283\nmicroservices quadrant, 283\nmicroservices system\nteam design and, 16\nmake commands, 215\nKubernetes, 160\nmonolithic data management, 79\nJSON data type, 211\nKubernetes secrets, 240\nNodebootstrap microservice, 213\nEKS (Elastic Kubernetes Service), 160, 164\ndesign, 202-208\nYAML file, 49\nKubernetes\nDeployment controller, 248\nteams and, 16\nplatform teams, 22, 29-30, 270\nKubernetes, 140, 247\nmicroservice deployment, 249-250\nACID and, 84\nKubernetes\nEKS (Elastic Kubernetes Service), 162, 164\nendpoint design, 198\nServices, Kubernetes, 248\nflights microservice, 244-246\nteams, 18-19\ndatabase module, 234\nstream-aligned teams, 22, 27\nEKS (Elastic Kubernetes Service), 148\ndesign), 65\nsyncing microservices, 257-259\nsystem design team, 24\nteam design, 8\nTeam Topologies, 21\nconsumer teams, 32-33\ndesigning, 24\nteams\nsystem design, 24\ntechnology architecture, 5\ndeployment, 250\nteams, 26-29\nJSON-based state file, 115\nflight microservice, 259-260\nup and running microservices model\ndata design, 9\nmicroservice design, 9\nmicroservice development, 9\nteam design, 8\nKubernetes module, 168-169\nmicroservices\nX-as-a-service interaction mode, Team Topol‐\ndeployment object, 247, 251\nHe is the coauthor of Microservice\nArchitecture and Continuous API Management (both O’Reilly).\nCorporation, leading the teams responsible for building Capital One’s modern, cloud\nnative, microservices-based core banking platform.\nis the coauthor of Microservice Architecture (O’Reilly).\nThe animal on the cover of Microservices: Up and Running is the sparkling violetear",
    "keywords": [
      "microservices",
      "Elastic Kubernetes Service",
      "microservices architecture",
      "microservices transformation",
      "Kubernetes",
      "teams",
      "design",
      "data",
      "Kubernetes Service",
      "Complexity",
      "team",
      "Elastic Kubernetes",
      "Amazon Web Services",
      "architecture",
      "system"
    ],
    "concepts": [
      "microservices",
      "microservice",
      "teams",
      "team",
      "designing",
      "design",
      "designers",
      "designs",
      "deployed",
      "deploy"
    ]
  }
]